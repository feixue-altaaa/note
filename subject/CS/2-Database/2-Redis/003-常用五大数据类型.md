![img](https://raw.githubusercontent.com/feixue-altaaa/picture/master/pic/202306142242559.png)

![img](https://img-blog.csdnimg.cn/img_convert/9d5433b75db5ac4320dc8c3a65d5c841.png)

#  String

##  简介

- String是Redis最基本的类型，一个key对应一个value

- String类型是**二进制安全**的。意味着Redis的string可以包含任何数据。比如jpg图片或者序列化的对象
- String类型是Redis最基本的数据类型，一个Redis中字符串value最多可以是**512M**
- **使用SDS可以减少修改字符串的内存重新分配次数**

> ## 二进制安全
>
> 二进制安全是指，在传输数据时，保证二进制数据的信息安全，也就是不被篡改、破译等，如果被攻击，能够及时检测出来
>
> 二进制安全包含了密码学的一些东西，比如加解密、签名等
>
> 举个例子，你把数据11110000加密成10001000，然后传给我，就是一种二进制安全的做法

##  数据结构

+ String的数据结构为**简单动态字符串**(Simple Dynamic String,缩写SDS)。是可以修改的字符串，内部结构实现上类似于Java的ArrayList，采用预分配冗余空间的方式来减少内存的频繁分配
  ![img](https://raw.githubusercontent.com/feixue-altaaa/picture/master/pic/202303131624273.png)
+ 如图中所示，内部为当前字符串实际分配的空间capacity一般要高于实际字符串长度len。当字符串长度小于1M时，扩容都是加倍现有的空间，如果超过1M，扩容时一次只会多扩1M的空间。需要注意的是字符串最大长度为512M
+ 一般来说，SDS 除了保存数据库中的字符串值以外，**还可以作为缓冲区（Buffer）**：包括 AOF 模块中的 AOF 缓冲区以及客户端状态中的输入缓冲区

#  List
##  简介
### 单键多值

+ Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边），它的底层实际是个**双向链表**，对两端的操作性能很高，通过索引下标的操作中间的节点性能会较差
  ![img](https://raw.githubusercontent.com/feixue-altaaa/picture/master/pic/202303131626811.jpeg)

##  数据结构
+ 列表对象的编码有 ziplist 和 linkedlist 两种。当列表的长度小于 512，并且所有元素的长度都小于 64 字节时，使用压缩列表存储，否则使用 linkedlist 存储

## 特性

- 双端：链表具有前置节点和后置节点的引用，获取这两个节点时间复杂度都为 O(1)

- 无环：表头节点的 prev 指针和表尾节点的 next 指针都指向 NULL,对链表的访问都是以 NULL 结束

- 带长度计数器：通过 len 属性获取链表长度的时间复杂度为 O(1)

- 多态：链表节点使用指针来保存节点值，可以保存各种不同类型的值

#  Set

##  简介
- Redis set对外提供的功能与list类似是一个列表的功能，特殊之处在于set是可以**自动排重**的，当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的
- Redis的Set是string类型的无序集合。它底层其实是一个value为null的**hash表**，所以添加，删除，查找的**复杂度都是O(1)**
- 一个算法，随着数据的增加，执行时间的长短，如果是O(1)，数据增加，查找数据的时间不变

## 应用场景

+ 好友关系

##  数据结构

+ 列表对象的编码有 intset 和 hashtable 两种。当集合的长度小于 512，并且所有元素都是整数时，使用整数集合存储；否则使用 hashtable 存储

#  Hash
##  简介
- Redis hash 是一个键值对集合
- Redis hash是一个string类型的field和value的映射表，hash特别适合用于存储对象
- 类似Java里面的Map<String,Object>

##  数据结构
+ 哈希对象的编码有 ziplist 和 hashtable 两种。当哈希对象保存的键值对数量小于 512，并且所有键值对的长度都小于 64 字节时，使用压缩列表存储；否则使用 hashtable 存储

#  Zset(sorted set) 
##  简介
- Redis有序集合zset与普通集合set非常相似，是一个没有重复元素的字符串集合
- 不同之处是有序集合的每个成员都关联了一个**评分（score）**,这个评分（score）被用来按照从最低分到最高分的方式排序集合中的成员。集合的成员是唯一的，但是评分可以是重复了 
- 因为元素是有序的, 所以你也可以很快的根据评分（score）或者次序（position）来获取一个范围的元素
- 访问有序集合的中间元素也是非常快的，因此你能够使用有序集合作为一个没有重复成员的智能列表

## 应用场景

- 排行榜

##  数据结构

+ SortedSet(zset)是Redis提供的一个非常特别的数据结构，一方面它等价于Java的数据结构Map<String,Double>，可以给每一个元素value赋予一个权重score，另一方面它又类似于TreeSet，内部的元素会按照权重score进行排序，可以得到每个元素的名次，还可以通过score的范围来获取元素的列表
+ zset底层使用了两个数据结构
  - **hash**，hash的作用就是关联元素value和权重score，保障元素value的唯一性，可以通过元素value找到相应的score值
  - **跳跃表**，跳跃表的目的在于给元素value排序，根据score的范围获取元素列表

###  跳跃表（跳表）
####  简介
+ 有序集合在生活中比较常见，例如根据成绩对学生排名，根据得分对玩家排名等。对于有序集合的底层实现，可以用数组、平衡树、链表等。数组不便元素的插入、删除；平衡树或红黑树虽然效率高但结构复杂；链表查询需要遍历所有效率低。Redis采用的是跳跃表。跳跃表效率堪比红黑树，实现远比红黑树简单
+ 跳表是一种高效的动态数据结构，它是基于链表实现的。在遍历有序单链表中，需要从头指针开始遍历，逐个节点的遍历，直到链表最后一个节点，需要遍历的节点个数是 n。如果，我们现在做一点改变，在遍历时，不是逐个节点遍历，而是每次遍历 2 个节点，那么遍历一遍同样大小的链表，需要遍历的节点个数是 n÷2+1。如果每次遍历的节点个数是 4 个，那么需要遍历的节点个数为 n÷4+1；类似的，一次遍历 n 个节点呢，就只需要遍历 2 个节点，整个链表就遍历完成了

####  实例
+ 基于上述思想，我们可以在原始单链表的基础上，每两个节点抽出一个节点，建立第一层索引，第一层索引的节点总数就为 n÷2。在第一层索引的节点基础上，每两个节点再抽出一个节点，建立第二层索引，那么第二次索引的节点总数为 *n*÷4。类似的方式，我们建立第 k 层索引时，节点总数为 n*÷(2*^k)。如果 n÷(2^k)=2，那么 k = log(*n*)−1。再加上原始单链表这一层，那么整个高度就是log(*n*)。当我们在跳表中查找一个数据时，需要从最上层索引开始查找，逐层往下层找，直到原始单链表这一层。如果每一层查找，需要遍历 m 个节点，那么整个查找需要遍历的总节点个数为m*∗log(*n)。由于我们是每两个节点抽出的一个节点去建立索引，所以每一层最多需要遍历 3 个节点，即 m = 3。跳表的查询时间复杂度就为3∗log(n)，用大 O 表示法，常数可以省略，记为 **O(log(n))**

![image-20190512115146755](https://raw.githubusercontent.com/feixue-altaaa/picture/master/pic/202303131649472.png)

# 单实例存储

## key数量

**What is the maximum number of keys a single Redis instance can hold? and what the max number of elements in a Hash, List, Set, Sorted Set?**

- Redis can handle up to 2^32 keys, and was tested in practice to handle at least 250 million keys per instance.
- Every hash, list, set, and sorted set, can hold 2^32 elements.
- In other words your limit is likely the available memory in your system.

## 单个key存储上限

**一个key或是value大小最大是512M**

![img](https://img-blog.csdn.net/20180619084655428?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTEzODM1OTY=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

## [Redis数据结构存储实验](https://www.jianshu.com/p/8f77c6764864)

Redis常用的有五大数据结构，包括String、List、Hash、Set、SortSet，那么存入相同大小的数据，这些数据结构所占的内存大小都是多少呢？下面做个实验，看看这些不同数据结构存储同样的100W数据，所占用的内存及查询时间。这里的100W数据指的是key和value总和，数据均采用32位UUID，Hash的field和SortSet的score使用一到两位字符存储，占有内存忽略不计

思路： 依次往各数据结构添加100W数据，选第10000个key作为查询key，添加完成后使用redis的 info‘memory’命令查看内存占用情况，计算查询key的检索时间，以纳秒为单位，完成统计后使用flushAll命令清空库，再进行一下个数据结构统计，实验结果如下

**String结构**

+ 占用内存：73.63M，查询key时长：130961 ns

**List结构**

+ 占用内存：37.48M，查询key时长：80195 ns（通过pop命令出队）

**Hash结构**

+ 占用内存：41.11M，查询key时长：77621 ns

**Set结构**

+ 占用内存：93.10M，查询key时长：5495122 ns（通过 smembers命令获取key集合全部成员）

**SortSet结构**

+ 占用内存：41.11M，查询key时长：228546 ns（通过zrange命令获取key有序集合成员）

**结论**

+ Key-Value结构查询速度更快，时间复杂度为O(1)，但会消耗更多内存，相比之下，Hash更优于Set、String结构，如果单纯的存储和查询，不做集合、排序处理，优先选择Hash结构。List不适合做检索，SortSet为有序集合，采用skiplist结构，检索速度比哈希略慢

## [Redis zset排行榜究竟能存多少数据（测试分析）](https://blog.csdn.net/humorchen99/article/details/128598936)

redis的[zset](https://so.csdn.net/so/search?q=zset&spm=1001.2101.3001.7020)非常适合用来做排行榜，可排行榜能容纳多少人呢？理论上来说redis zset的跳表能存2^32次方条数据进去，可是实践中能存多少你也不清楚的，万一应用中翻车了呢？所以需要提前测试测试

我[电脑配置](https://so.csdn.net/so/search?q=电脑配置&spm=1001.2101.3001.7020)如下，使用自己电脑windows10操作系统进行测试，结果与linux我觉得相差不会很大的，这数据是存储到运行内存的

![在这里插入图片描述](https://img-blog.csdnimg.cn/a9560d8827294684b422d319762ed6a1.png)

批量生成数据插入zset的lua脚本如下

```lua
local i = 10000000
while( i < 110099999)
do
    redis.call('zadd','testzset',i%13579,i)
    i = i +1
end

# 执行命令如下
redis-cli --eval ./test.lua
```

- 初始时电脑已使用内存为8.5GB，在插入数据到一亿时内存到了97%，插入脚本被阻塞住了，没有内存给它用了。。。只好shutdown nosave关闭掉redis服务器来释放内存
- 往zset插入一亿条8位ID+5位内score耗费掉了我14GB左右内存。快照rdb文件900M（里面九千万条已保存数据），重启redis恢复快照耗费755秒（恢复期间与脚本批量生成数据期间无法执行redis读写命令，因此不要对大家都在用的redis去做这样的操作）
- 恢复九千万条数据后对该zset进行zrevrange、zcard操作还是很顺畅丝滑立即出结果的，性能挺不错。
  但是不建议一次查询过多数据，会堵塞redis的IO，影响其他业务使用redis，应当采取分页、计算关键数据这些方式来查询数据，让一次redis操作返回的数据量比较小
- 从目前测试的情况来看redis zset做排行榜还是不错的，存下一亿条数据也可以做到，但是这样一个榜单就会占十多GB内存，可贵了！要便宜的话还是用磁盘存的数据库吧，然后牺牲下排行榜的实时性，调度定时来更新前多少名，再固定存到磁盘，加上本地缓存来实现接口大量查询

## [redis的map和zset写入50万个数据的测试结果](https://blog.csdn.net/wgw335363240/article/details/103326034)

**需求描述**

- 某个项目中需要使用缓存工具缓存55万个分类信息，然后对每个分类进行计数统计，调研了redis的hashmap和zset的性能，最终决定使用zset。原因如下
  - hashmap和zset都写入55万个key，zset约要34秒，hashmap约要39秒
  - hashmap读取55万个key的耗时3.3秒，zset读取55万个key约耗时1.4秒
  - hashmap存储的key是无序的，zset存储的value是有序的

```java
public void TestReadRedis() throws Exception {
        String sRedisHost = "127.0.0.1";
        int nRedisPort = 6379;
        int REDIS_DBIDX = 0;
        int REDIS_POOLSIZE = 20;
        RedisApi redisApi = new RedisApi(sRedisHost, nRedisPort, REDIS_DBIDX, REDIS_POOLSIZE);

        String sRedisKey = "my_map_key";
        HashMap<String, String> mapKeyValue = new HashMap<>();
        long lTime98 = System.currentTimeMillis();
        for (int i = 0; i <= 550000; i++) {
            String sMapKey = String.format("key_%s", i);
            mapKeyValue.put(sMapKey, String.valueOf(i));
            if (i % 10000 == 0) {
                //System.out.println("map i=" + i);
                redisApi.hmset(sRedisKey, mapKeyValue, -1);
                mapKeyValue.clear();
            }
        }
        if (mapKeyValue.size() > 0) {
            System.out.println(mapKeyValue.size());
            redisApi.hmset(sRedisKey, mapKeyValue, -1);
        }
        long lTime99 = System.currentTimeMillis();
        System.out.println("写入map耗时：" + (lTime99 - lTime98));

        long lTime1 = System.currentTimeMillis();
        Map<String, String> hMapGetValue = redisApi.hgetAll(sRedisKey);
        long lTime2 = System.currentTimeMillis();

        System.out.println("读取map用时：" + (lTime2 - lTime1) + ",size=" + hMapGetValue.size());

        //测试zset的效果
        String sRedisSetKEey = "my_set_key";
        long lTime3 = System.currentTimeMillis();
        Map<String, Double> hScoreMembers = new HashMap<>();
        Double dScore = Double.valueOf(1);
        for (int i = 0; i <= 550000; i++) {
            String sMapKey = String.format("key_%s", i);
            hScoreMembers.put(sMapKey, dScore);
            if (i % 10000 == 0) {
                //System.out.println("zset i=" + i);
                redisApi.zadd(sRedisSetKEey, hScoreMembers, -1);
                hScoreMembers.clear();
            }
        }
        if (hScoreMembers.size() > 0) {
            System.out.println("hScoreMembers.size=" + hScoreMembers.size());
            redisApi.zadd(sRedisSetKEey, hScoreMembers, -1);
        }
        long lTime4 = System.currentTimeMillis();
        System.out.println("写入zset耗时： " + (lTime4 - lTime3));


        long lTime5 = System.currentTimeMillis();
        Set<String> setGetValue = redisApi.zrange(sRedisSetKEey, 0, -1);
        long lTime6 = System.currentTimeMillis();
        System.out.println("读取zset用时：" + (lTime6 - lTime5) + ",size=" + setGetValue.size());
    }
```

**结果如下**

```
写入map耗时：39497 
读取map用时：3343,size=550001
写入zset耗时： 34992
读取zset用时：1429,size=550001
```

# Redis底层实现

+ 在Redis中，键值对（Key-Value Pair）存储方式是由字典（Dict）保存的，而字典底层是通过哈希表来实现的。通过哈希表中的节点保存字典中的键值对。我们知道当HashMap中由于Hash冲突（负载因子）超过某个阈值时，出于链表性能的考虑，会进行Resize的操作。Redis也一样

## 什么是渐近式 rehash？

- 也就是说扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。 如果保存在 Redis 中的键值对只有几个几十个，那么 rehash 操作可以瞬间完成，但是如果键值对有几百万，几千万甚至几亿，那么要一次性的进行 rehash，势必会造成 Redis 一段时间内不能进行别的操作。所以 Redis 采用渐进式 rehash
- 这样在进行渐进式 rehash 期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行增加操作，一定是在新的哈希表上进行的

# 什么是 RedisObject？
+ 我们知道，Redis 底层实现了很多高级数据结构，如简单动态字符串、双端链表、字典、压缩列表、跳跃表、整数集合等。然而 Redis 并没有直接使用这些数据结构来实现键值对的数据库，而是在这些数据结构之上又包装了一层 RedisObject（对象），也就是我们常说的五种数据结构：字符串对象、列表对象、哈希对象、集合对象和有序集合对象
  ```c
  typedef struct redisObject {
      // 类型
      unsigned type:4;
      // 编码，即对象的底层实现数据结构
      unsigned encoding:4;
      // 对象最后一次被访问的时间
      unsigned lru:REDIS_LRU_BITS;
      // 引用计数
      int refcount;
      // 指向实际值的指针
      void *ptr;
  } robj;
  ```

**这样做有两个好处**

- 通过不同类型的对象，Redis 可以在执行命令之前，根据对象的类型来判断一个对象是否可以执行该的命令
- 可以针对不同的使用场景，为对象设置不同的实现，从而优化内存或查询速度

# redis常见数据类型操作命令

