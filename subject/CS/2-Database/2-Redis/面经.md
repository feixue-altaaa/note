# redis为什么快

- 内存存储：Redis 将数据存储在内存中，而不是硬盘上，因此可以快速读写数据。内存的读写速度比硬盘快得多

- 单线程模型：Redis 是单线程模型的，这意味着 Redis 在任何时候都只有一个线程在执行，避免了**线程切换**和**上下文切换**的开销，从而提高了性能

  > **并发(concurrency)**：指在同一时刻只能有一条指令执行，但多个进程指令被快速的轮换执行，使得在宏观上具有多个进程同时执行的效果，但在微观上并不是同时执行的，只是把时间分成若干段，使多个进程快速交替的执行。
  > **并行(parallel)**：指在同一时刻，有多条指令在多个处理器上同时执行。所以无论从微观还是从宏观来看，二者都是一起执行的

  > **上下文切换**
  >
  > 多个线程可以执行在单核或多核CPU上，单核CPU也支持多线程执行代码，CPU通过给每个线程分配CPU时间片(机会)来实现这个机制。CPU为了执行多个线程，就需要不停的切换执行的线程，这样才能保证所有的线程在一段时间内都有被执行的机会。
  >
  > 此时，CPU分配给每个线程的执行时间段，称作它的时间片。CPU时间片一般为几十毫秒。CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后切换到下一个任务。
  >
  > 但是，在切换前会保存上一个任务的状态，以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换。
  >
  > 根据多线程的运行状态来说明：多线程环境中，当一个线程的状态由Runnable转换为非Runnable(Blocked、Waiting、Timed_Waiting)时，相应线程的上下文信息(包括CPU的寄存器和程序计数器在某一时间点的内容等)需要被保存，以便相应线程稍后再次进入Runnable状态时能够在之前的执行进度的基础上继续前进。而一个线程从非Runnable状态进入Runnable状态可能涉及恢复之前保存的上下文信息。这个对线程的上下文进行保存和恢复的过程就被称为

-  IO 多路复用：Redis 将所有产生事件的套接字都放到一个队列里面，以有序、同步、每次一个套接字的方式向文件事件分派器传送套接字，文件事件分派器根据套接字对应的事件选择响应的处理器进行处理，从而实现了高效的网络请求

- 数据结构简单：Redis 支持多种数据结构，如字符串、哈希表、列表、集合等，这些数据结构都是基于简单的键值对存储的，因此可以快速读写数据

# redis 一致性哈希 场景 解决的问题

## why

+ 常用的hash算法虽然能建立数据和节点的映射关系，但每次在节点数量发生变化的时候，最坏情况下所有数据都需要迁移，因此不适用节点数量变化的分布式场景。**为了减少迁移的数据量，就出现了一致性hash算法**

## what

![image.png](https://raw.githubusercontent.com/feixue-altaaa/picture/master/pic/202306151447761.webp)

+ 一致性hash是指将 “**存储节点**” 和 “**数据**” 都映射到一个首尾相连的hash环上。如果增删节点，仅影响该节点在hash环上顺时针相邻的后继节点，其他数据不会受到影响
+ 第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希（用ip地址对环上的节点个数进行hash，比如ip地址为1.2.3.4，节点个数N，那么可映射到第1234%N的位置上）；
+ 第二步：当对数据进行存储或访问时，对数据进行哈希映射；
  + 一致性Hash算法使用 “取模法”，且是对 2^32 次方取模，其可表示的范围为：0 ~ 2^32-1

> **如何确定数据位于hash环上的位置？**
>
> > 将数据key使用Hash函数计算出哈希值，并确定此数据在环上的位置，从此位置沿环**顺时针**行走，第一台遇到的服务器就是其应该定位到的服务器！
> > 比如：a、b、c三个key，经过哈希计算后，在环空间上的位置如下：key-a存储在node1，key-b存储在node2，key-c存储在node3。
> >
> > **与普通的hash算法有何不同？**
> > 普通的hash算法是对节点数进行hash，而**一致性hash是对固定值 2^32 进行取模**

## 应用场景：分布式缓存系统

## 优点

+ 一致性Hash算法对于节点的增减都只需重定位环空间中的一小部分数据，具有较好的**容错性和可扩展性。**

+ 新增服务器节点/删除服务器节点： 在hash环中新增服务器，也是通过hash算法确认分布，只需要移动一小部分数据即可；移除也是同理（比如下图中想删除4节点，只需把原本1~4节点之间的数据移动到2节点上即可）

![image.png](https://raw.githubusercontent.com/feixue-altaaa/picture/master/pic/202306151449093.webp)

## 缺点

### **易产生数据倾斜**

- 一致性哈希算法不能够均匀的分布节点，会出现大量请求都集中在一个节点的情况，在这种情况下进行容灾与扩容时，容易出现雪崩的连锁反应
-  当在服务器节点数量太少的时候，容易出现分布不均而导致数据倾斜

### 数据倾斜解决方法：虚拟节点映射

+ 为了解决一致性哈希算法不能够均匀的分布节点的问题，就需要引入虚拟节点，对一个真实节点做多个副本。不再将真实节点映射到哈希环上，而是将虚拟节点映射到哈希环上，并将虚拟节点映射到实际节点，所以这里有「两层」映射关系

> 映射关系：缓存数据 ➜ 虚拟节点 ➜ 真实节点

+ 具体做法：可以在服务器IP或主机名的后面增加编号来实现，例如上面的情况，可以为每个服务节点增加三个虚拟节点，于是可以分为： RedisService1#1、 RedisService1#2、 RedisService1#3、 RedisService2#1、 RedisService2#2、 RedisService2#3

+ 对于hash环来说，节点越多，数据分布越平稳。所以采用虚拟节点的方式，将一个节点虚拟成多个节点，保证环上有1000~2000个节点最佳。

- 一般10个Redis服务器的集群，每个节点可以虚拟100-200个节点，保证环上有1000-2000个节点
- 一般5个Redis集群，则每个节点虚拟200-400个节点，保证节点数是1000-2000之间，这样才能保证数据分布均衡

 **引入虚拟节点后，会提高节点的均衡度，还会提高系统的稳定性**

# MySQL 跟 redis 适用场景区别

## redis 适用场景

+ 缓存
+ 排行榜
+ 好友关系
+ 计算机
+ 限流
+ 发布、订阅

## MySQL适用场景

- 数据需要长期存储，且需要支持复杂的查询和事务处理
- 数据需要保证一致性和完整性

#### Web 网站系统

- Web 网站开发者是 MySQL 最大的客户群，也是 MySQL 发展史上最为重要的支撑力量。
- MySQL 之所以能成为 Web 网站开发者们最青睐的数据库管理系统，是因为 [MySQL 数据库](https://cloud.tencent.com/product/cdb?from=20065&from_column=20065)的安装配置都非常简单，使用过程中的维护也不像很多大型商业数据库管理系统那么复杂，而且性能出色。还有一个非常重要的原因就是 MySQL 是开放源代码的，完全可以免费使用

#### 日志记录系统

+ MySQL 数据库的插入和查询性能都非常的高效，如果设计的好，在使用 MyISAM 存储引擎的时候，两者可以做到互不锁定，达到很高的并发性能。所以，对需要大量的插入和查询日志记录的系统来说，MySQL 是非常不错的选择。比如处理用户的登录日志，操作日志等，都是非常适合的应用场景

# redis和caffine区别

> Caffeine的底层数据存储采用ConcurrentHashMap

- 数据存储方式
  - Redis：Redis 通过网络提供对内存中数据的访问和操作（但不是本地内存，是服务器内存）
  - Caffeine：Caffeine 将数据存储在应用程序的本地内存中，而不是存储在远程服务器上，因此对于小型应用程序而言，使用 Caffeine 可以降低网络开销
- 数据一致性
  - Redis：Redis支持分布式部署，可以通过主从复制或集群模式实现高可用和数据一致性。它提供了持久化机制，可以将数据写入磁盘，以防止数据丢失
  - Caffeine：Caffeine是一个本地缓存库，不支持分布式部署。它适用于单个应用程序的缓存需求

# 如何提高缓存利用率

**LRU 淘汰算法**

把不常用的数据放到缓存里，会占用内存，降低缓存利用率，所以想要提高缓存的利用率，比较容易想到的方案就是：Redis 缓存中只保留最近访问比较多的数据，我们将这些数据称为“**热数据**”。具体实现如下

- 写数据依然是写到数据库；
- 读请求先从缓存里读，如果读取的数据不在缓存，则从数据库读取，并将读取的数据刷到缓存；
- 另外，刷到缓存中的数据，都需要设置失效时间

将缓存的数据设置了失效时间，这样缓存中如果不经常访问的数据，就会随着时间被过期淘汰掉，缓存剩下的都是经常被访问到的“**热数据**”，从而提高了缓存的利用率，其实就是 LRU 淘汰算法

> - 先进先出FIFO（First In，First Out）
> - 最少使用策略LFU（Least Frequently Used）
> - 最近最少使用策略LRU（Least Recently Used）

# 数据库和缓存的一致性问题

### 先更新数据库，再更新缓存

- 先更新数据库，再更新缓存的情况下：如果数据库更新成功了，但是缓存更新失败，则数据库的数据是新的值，缓存中的数据还是旧数据
- 接下来，有读请求进来，读缓存读到的是旧数据（缓存失效前），只直当缓存失效后，才会从数据库中读到最新值，然后重建缓存，此时缓存的数据才是最新的
- 如果缓存失效前用户来读的数据，会发现前面修改的数据还没生效，一段时间后，数据才更新过来，这样会对业务有影响

### 先更新缓存，在更新数据库

- 先更新缓存，在更新数据库的情况下：如果缓存更新成功了，但是数据库更新失败，则缓存的数据是新的值，数据库中的数据还是旧数据。
- 接下来，有读请求进来，虽然可以命中缓存，读到的是新的值，即正确的值，但是缓存一旦失效，就会从数据库中读取旧数据，然后重建缓存，这样缓存的数据也是旧的了。
- 此时用户又过来读数据，会发现之前修改的数据又变回旧的数据了，同样会对业务有影响。
- 综上两种方案所述：无论先更新谁，但凡后者更新发生了异常，都会对业务造成一定的影响

### 先删除缓存，再更新数据库

- 假设 X 原值为 1，有线程 A 和 B
  - A 要更新数据（X = 2），先删除缓存；
  - B 读缓存，发现不存在，从数据库中读取数据（X = 1）；
  - A 将新值（X = 2）写入数据库；
  - B 将旧数据（X = 1）写入缓存；
- 根据以上执行顺序可知，最后缓存中 X 的值是 1（旧数据），在数据库中的值是 2（新值），数据不一致。
- 可见，“**先删除缓存，后更新数据库**”的方案，当发生「读+写」并发时，还是会存在数据不一致的情况

### 先更新数据库，再删除缓存

- 同样有线程 A 和 B 并发操作
  - 缓存中不存在 X 数据，数据库中存在 X = 1；
  - A 读取数据库，得到 X = 1；
  - B 更新数据库 X = 2；
  - B 删除缓存；
  - A 将 X = 1（旧值） 写入缓存；
- 最后缓存中 X 的值是 1（旧值），数据库中的值是 2 （新值），数据不一致。
- 这种情况理论上来说是有可能发生的，但实际上其实发生的**概率很低**，因为这种情况是需要满足下面三个条件才会发生的
  - 首先缓存是已失效，即缓存不存在该条数据；
  - 读和写请求该条数据一起并发过来；
  - 更新数据库和删除缓存的时间（上面步骤 3 和 4），要比读数据库和写缓存的时间短（上面步骤 2 和 5）；
- 根据多年的开发经验，条件 3 发生的概率其实是比较低的。
- 因为写数据库操作一般会先**加锁**，所以写数据库操作通常是要比读数据库操作的时间更长些。
- 综上所述，“**先更新数据库，再删除缓存**”的方案，在一定程度上是可以保证数据一致性的。
- 所以，在平时开发中，我们应该采用此种方案，来操作数据库和缓存。
- 到这里，并发带来的问题也就解决了，接下来我们继续看前面提到的问题： **第二步执行「失败」或异常，导致数据不一致的问题**

## 如何确保更新数据库和删除缓存这两步操作都执行成功？

+ 前面已经分析到：无论是更新缓存还是删除缓存，但凡第二步发生失败，就会导致数据库和缓存不一致的问题。那么该如何解决此问题呢？

### 方案一：重试

+ 首先想到的一个方案是：执行失败后，**重试**

### 方案二：异步重试

- 异步重试其实就是：把重试请求扔到消息队列中，然后由专门的消费者来重试，直到成功
- 到这里，有些人可能又会注意到，写消息队列也有可能会失败的吧？而且，另外引入消息队列，这不仅增加系统的复杂性，而且增加了更多的维护成本，划得来吗？
- 这个问题问的好，只有不断的思考，提出问题，解决问题，才会有进步
- 在回答上面那个问题前，我们先来思考这样的一个问题：如果不把重试的操作仍到消息队列，在执行失败的线程中一直重试，还没等重试执行成功，此时如果该进程「重启」了，那这次重试请求也就「丢失」了，那这条数据就确确实实的不一致了（再也没机会了）
- 所以，这里我们把重试或第二步操作放到另一个**服务**中，这个服务用消息队列来进行重试操作

# 如何保证 Redis 的高并发？

+ Redis 通过**主从加集群**架构，实现读写分离，主节点负责写，并将数据同步给其他从节点，从节点负责读，从而实现高并发

# Redis 如何保证原子性？

- 答案很简单，因为 Redis 是单线程的，所以 Redis 提供的 API 也是原子操作
- 但我们业务中常常有先 get 后 set 的业务常见，在并发下会导致数据不一致的情况


**如何解决**

- 使用 incr、decr、setnx 等原子操作；

- 客户端加锁；

- 使用 Lua 脚本实现 CAS 操作

# Zset 为何不使用红黑树等平衡树？

- 跳跃表范围查询比平衡树操作简单。 因为平衡树在查询到最小值的时还需要采用中序遍历去查询最大值。 而跳表只需要在找到最小值后，对第一层的链表遍历即可。
- 平衡树的删除和插入需要对子树进行相应的调整，而跳表只需要修改相邻的节点即可。
- 跳表和平衡树的查询操作都是O（logN）的时间复杂度。

- 从整体上来看，跳表算法实现的难度要低于平衡树

# 什么是渐近式 rehash？

- 也就是说扩容和收缩操作不是一次性、集中式完成的，而是分多次、渐进式完成的。 如果保存在 Redis 中的键值对只有几个几十个，那么 rehash 操作可以瞬间完成，但是如果键值对有几百万，几千万甚至几亿，那么要一次性的进行 rehash，势必会造成 Redis 一段时间内不能进行别的操作。所以 Redis 采用渐进式 rehash。
- 这样在进行渐进式 rehash 期间，字典的删除查找更新等操作可能会在两个哈希表上进行，第一个哈希表没有找到，就会去第二个哈希表上进行查找。但是进行增加操作，一定是在新的哈希表上进行的

# 什么是 Redis 的 intset？

**整数集合（intset）** 是 Redis 用于保存**整数值的集合**抽象数据类型，它可以保存类型为 int16_t、int32_t 或者 int64_t 的整数值，并且保证集合中不会出现重复元素

```c
typedef struct intset{
     //编码方式
     uint32_t encoding;
     //集合包含的元素数量
     uint32_t length;
     //保存元素的数组
     int8_t contents[];

}intset;
```

整数集合的每个元素都是 contents 数组的一个数据项，它们按照从小到大的顺序排列，并且不包含任何重复项。需要注意的是虽然 contents 数组声明为 int8_t 类型，但是实际上 contents 数组并不保存任何 int8_t 类型的值，其真正类型有 encoding 来决定

## 集合升级过程

当我们新增的元素类型比原集合元素类型的长度要大时，需要对整数集合进行升级，才能将新元素放入整数集合中。具体步骤

- 根据新元素类型，扩展整数集合底层数组的大小，并为新元素分配空间

- 将底层数组现有的所有元素都转成与新元素相同类型的元素，并将转换后的元素放到正确的位置，放置过程中，维持整个元素顺序都是有序的

- 将新元素添加到整数集合中（保证有序）


## 集合是否降级

整数集合不支持降级操作，一旦对数组进行了升级，编码就会一直保持升级后的状态

# Redis 有哪些内存淘汰机制？

Redis 作为一个内存数据库，在内存空间不足的时候，为了保证命中率，就会和我们操作系统中的页面置换算法类似，选择一定的数据淘汰策略。有八种数据淘汰策略

**volatile（设置过期时间的数据集）**

- volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的数据淘汰
- volatile-ttl：从已设置过期时间的数据集中挑选将要过期的数据淘汰

- volatile-random：从已设置过期时间的数据集中任意选择数据淘汰

- volatile-lfu：从已设置过期时间的数据集挑选使用频率最低的数据淘汰


**allkeys（所以数据集）**

- allkeys-lru：从数据集中挑选最近最少使用的数据淘汰
- allkeys-lfu：从数据集中挑选使用频率最低的数据淘汰

- allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰


**no-enviction**

- no-enviction（驱逐）：禁止驱逐数据，这也是默认策略。

- 意思是当内存不足以容纳新入数据时，新写入操作就会报错，请求可以继续进行，线上任务也不能持续进行，采用 no-enviction 策略可以保证数据不被丢失

# 什么是 Redis 的 Pipeline？

- 在出现 Pipeline 之前，我们梳理一下 Redis 客户端执行一条命令需要经过哪些步骤： 发送命令－〉命令排队－〉命令执行－〉返回结果
- 这个过程称为 Round trip time(简称RTT, 往返时间)，mget 和 mset 有效节约了 RTT，但大部分命令（如 hgetall 并没有 mhgetall）不支持批量操作，需要消耗 N 次 RTT ，这个时候需要 pipeline 来解决这个问题
  ![img](https://raw.githubusercontent.com/feixue-altaaa/picture/master/pic/202307032009230.png)

# 原生批命令 (mset, mget) 与 Pipeline 区别?

- 原生批命令是原子性的，而 pipeline 是非原子操作
- 原生批命令一命令多个 key, 但 pipeline 支持多命令（存在事务），非原子性

- 原生批命令是服务端实现，而 pipeline 需要服务端与客户端共同完成

# 为什么要用Redis而不直接用Map做缓存?

缓存分为本地缓存和分布式缓存。以java为例，使用自带的map或者guava实现的是本地缓存，最主要的特点是轻量以及快速，[生命周期](https://so.csdn.net/so/search?q=生命周期&spm=1001.2101.3001.7020)随着jvm的销毁而结束，并且在多实例的情况下，每个实例都需要各自保存一份缓存，缓存不具有一致性

使用redis或[memcached](https://so.csdn.net/so/search?q=memcached&spm=1001.2101.3001.7020)之类的称为分布式缓存，在多实例的情况下，各实例共用一份缓存数据，缓存具有一致性。缺点是需要保持redis或memcached服务的高可用，整个程序架构上较为复杂

当然如果只是将少量数据保存作为缓存并且没有持久化的需求，那么完全可以用Map做缓存

**详细的区别**

- Redis 可以用几十 G 内存来做缓存，Map 不行，一般 JVM 也就分几个 G 数据就够大了
- Redis 的缓存可以持久化，Map 是内存对象，程序一重启数据就没了
- Redis 可以实现分布式的缓存，Map 只能存在创建它的程序里
- Redis 单点吞吐量能达到10万级，是专业的缓存服务，Map 只是一个普通的对象
- Redis 缓存有过期机制，Map 本身无此功能
- Redis 有丰富的 API，Map 就简单太多了
- map需要扩容

# redis 6.0 多线程的实现机制

Redis官方在 2020 年 5 月正式推出 6.0 版本，提供很多振奋人心的新特性，所以备受关注。其主要特性如下：

- 多线程处理网络IO
- 客户端缓存
- 细粒度权限控制（ACL）；
- `RESP3`协议的使用
- 用于复制的RDB文件不再有用，将立即被删除
- RDB 文件加载速度更快；

## Redis 6.0之前的版本真的是单线程吗？

Redis是基于Reactor模式开发了网络事件处理器，这个处理器被称为文件事件处理器。他的组成分4部分

- 多个socket
- IO 多路复用
- 文件事件分派器
- 事件处理器

正因为文件事件分派器是单线程的，所以Redis才叫做单线程模型

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210527155815520.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoaWppbmdoYW4xMTI2,size_16,color_FFFFFF,t_70)

Redis之前用单线程模型，是因为性能不在CPU，而在内存和网络。如要用到CPU多核，可搭建多个Redis实例来解决

其实，Redis 4.0开始就有了多线程概念了，比如Redis通过多线程在后台删除对象

## redis 6.0 之前单线程指的是redis只有一个线程干活么？

不是，**Redis 在处理客户端的请求时，包括获取 (socket 读)、解析、执行、内容返回 (socket 写) 等都由一个顺序串行的主线程处理，这就是所谓的「单线程」**。

其中执行命令阶段，由于 Redis 是单线程来处理命令的，所有每一条到达服务端的命令不会立刻执行，所有的命令都会进入一个 Socket 队列中，当 socket 可读则交给单线程事件分发器逐个被执行

此外，有些命令操作可以用后台线程或子进程执行（比如数据删除、快照生成、AOF 重写）

![在这里插入图片描述](https://img-blog.csdnimg.cn/4e6a951f79d74bb58ccda2e94e8b4ab7.png?x-oss-process=image/watermark,type_ZHJvaWRzYW5zZmFsbGJhY2s,shadow_50,text_Q1NETiBAT2NlYW4mJlN0YXI=,size_20,color_FFFFFF,t_70,g_se,x_16)

## redis6.0之前为什么不使用多线程

多线程引入了程序执行顺序不确定的问题，且带来了线程切换、加锁等性能问题

Redis通过Reactor模型，性能已经非常好，没必要使用多线程。

且单线程使得redis内部实现复杂度大大降低，Hash的惰性Rehash, lpush等线程不安全的命令，都不必加锁

## Redis 6.0为什么要引入多线程

Redis的性能瓶颈不在CPU，而在内存和网络

内存不够，可以做数据结构优化。所以网络才是关键，网络IO在执行期间大量占用了CPU，所以如果网络IO时引入多线程，对性能提升很大

所以总结起来，Redis6.0支持多线程有两个原因

- 充分利用CPU多核，6.0之前主线程只能利用一个核
- 多线程任务可以分摊Redis同步IO读写负荷

看下官方发布的新版和旧版的性能对比

**get的性能对比**

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210527152535478.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoaWppbmdoYW4xMTI2,size_16,color_FFFFFF,t_70)

**set的性能对比**

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210527152610149.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoaWppbmdoYW4xMTI2,size_16,color_FFFFFF,t_70)

## Redis 6.0多线程的实现机制

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210527161504544.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoaWppbmdoYW4xMTI2,size_16,color_FFFFFF,t_70)

流程简述为

- 主线程负责接收并建立连接请求，获取socket放入全局等待读处理队列
- 主线程处理完读事件后，通过Round Robin讲这些连接分配给这些IO线程
- 主线程阻塞等待IO读取socket完毕
- 主线程通过单线程的方式执行请求命令，请求数据读取并解析完成，但并不执行
- 主线程阻塞等待IO线程将数据回写socket完毕
- 解除绑定，清空等待队列

也就是说，真正执行redis命令时，还是单线程的，如步骤4

多线程，发生在网络IO，步骤三和步骤五

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210527164717535.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NoaWppbmdoYW4xMTI2,size_16,color_FFFFFF,t_70)
## 开启多线程后，是否会存在线程并发安全问题？

**不会**

Redis多线程部分仅用于处理网络IO和协议解析

Redis执行命令仍然是单线程的
