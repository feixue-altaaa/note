# 什么是本地缓存

本地缓存是指和应用程序在同一个进程内的内存空间去存储数据，数据的读写都是在同一个进程内完成的

**本地缓存优点**

读取速度快，但是不能进行大数据量存储。

本地缓存不需要远程网络请求去操作内存空间，没有额外的性能消耗，所以读取速度快。

**本地缓存缺点**

**应用程序集群部署时，会存在数据更新问题（数据更新不一致）**

本地缓存一般只能被同一个应用进程的程序访问，不能被其他应用程序进程访问。在单体应用集群部署时，如果数据库有数据需要更新，就要同步更新不同服务器节点上的本地缓存的数据来保证数据的一致性，但是这种操作的复杂度高，容易出错。可以基于redis的发布/订阅机制来实现各个部署节点的数据同步更新

**数据会随着应用程序的重启而丢失**

因为本地缓存的数据是存储在应用进程的内存空间的，所以当应用进程重启时，本地缓存的数据会丢失

[什么是本地缓存、分布式缓存以及多级缓存？](https://cloud.tencent.com/developer/news/969299)

# 为什么要使用本地缓存

- 本地缓存基于**本地环境的内存，访问速度非常快**，对于一些变更频率低、实时性要求低的数据，可以放在本地缓存中，提升访问速度
- 使用本地缓存能够减少和Redis类的远程缓存间的数据交互，**减少网络I/O开销**，降低这一过程中在网络通信上的耗时

> JAVA 有了 ConcurrentHashMap 为什么还需要本地缓存?
>
> JDK内置的Map可作为缓存的一种实现方式，然而严格意义来讲，其不能算作缓存的范畴。原因如下：一是其存储的数据不能主动过期；二是无任何缓存淘汰策略

# 缓存淘汰算法

+ 缓存淘汰算法的作用是在有限的资源内,尽可能识别出哪些数据在短时间会被重复利用,从而提高缓存的命中率

## LRU (Least Recently Used)

- 该算法认为最近访问过的数据将来被访问的几率会更高,通常使用链表来实现
- 如果数据添加或被访问则把数据移动到链表的头部,链表的头部为热数据尾部则为冷数据,当数据满时淘汰尾部的数据


**缺点**

+ 如果一个元素只被访问一次，那么它也会把其他元素给挤出去。这样就会导致如果我们的缓存空间不够长，遇到突发的稀疏流量（比如列表遍历）将会把大量元素给挤出去，留下一堆很可能不会再次被访问的元素在缓存中，导致缓存命中率下降

**算法实现**

```java

```

## SLRU（Segmented LRU，分段最近最少使用缓存淘汰策略）

- 上面的LRU有一个问题，如果一个元素只被访问一次，那么它也会把其他元素给挤出去。这样就会导致如果我们的缓存空间不够长，遇到突发的稀疏流量（比如列表遍历）将会把大量元素给挤出去，留下一堆很可能不会再次被访问的元素在缓存中，导致缓存命中率下降
- 而SLRU就是把缓存分成两段，一段是`淘汰段`，一段是`保护段`，两个段都是普通的LRU实现。第一次被访问的元素将进入淘汰段，只有处于淘汰段中的元素再次被访问才会进入保护段。保护段中的元素如果被淘汰将会再次进入淘汰段，而淘汰段的元素被淘汰则会被移出缓存
- 简单来说就是每个元素至少两次被访问才会进入保护段，而保护段中的元素是受保护的，它更难被淘汰，因为就算被淘汰也只是移动到淘汰段
- 也就能更好的抵御突发的稀疏流量，保护段的元素不会被只访问过一次的元素给淘汰；空间不足时只会从淘汰段淘汰，保护段的元素不会被直接淘汰

![SLRU.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/db789e1a40c5488287446318babf5501~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

## LFU (Least FrequentlyUsed)

该算法根据数据的**历史访问频率来淘汰数据**,其核心思想是:如果数据过去被访问多次,那么将来被访问的频率也更高

根据LFU的思想如果想要实现这个算法,**需要额外去维护一套统计每个元素访问次数的逻辑**,会造成内存资源的浪费

**LFU的局限性**：在 LFU 中只要数据访问模式的概率分布随时间保持不变时，其命中率就能变得非常高。比如有部新剧出来了，我们使用 LFU 给他缓存下来，这部新剧在这几天大概访问了几亿次，这个访问频率也在我们的 LFU 中记录了几亿次。但是新剧总会过气的，比如一个月之后这个新剧的前几集其实已经过气了，但是他的访问量的确是太高了，其他的电视剧根本无法淘汰这个新剧，所以在这种模式下是有局限性

## FIFO (First In First Out)

先进先出的思想,判断被存储的时间,**离目前最远的数据优先被淘汰**.实现起来比较简单

## TinyLFU

**TinyLFU目的是为了解决传统LFU算法空间存储比较大的问题**,它也是基于LFU算法

它可以在**较大访问量的场景下替代LFU的数据统计部分**,原理有些类似BloomFilter(布隆过滤器)

> ## BloomFilter（布隆过滤器）
>
> 布隆过滤器（BloomFilter）是一种用于判断元素是否存在的方式，它的空间成本非常小，速度也很快。
>
> 但是由于它是基于概率的，因此它存在一定的误判率，它的`Contains()`操作如果返回`true`只是表示元素可能存在集合内，返回`false`则表示元素一定不存在集合内。因此适合用于能够容忍一定误判元素存在集合内的场景，比如缓存
>
> 布隆过滤器的数据结构是一个位向量，也就是一个由`0`、`1`所组成的向量（下面是一个初始向量）
>
> ![基础结构.png](https://raw.githubusercontent.com/feixue-altaaa/picture/master/pic/202309101613656.webp)
>
> 每个元素添加进布隆过滤器前，都会经过多个不同的哈希函数(通过多个哈希函数可以减小误判率)，计算出不同的哈希值，然后映射到位向量上，也就是对应的位上面置1
>
> ![哈希映射.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/7918ce837f4c46f0806fe5c545257bd2~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)
>
> 判断元素是否存在也是如上图流程，根据哈希函数映射的位置，判断所有映射位置是否都为1，如果是则元素可能存在，否则元素一定不存在
>
> 由于不同的值通过哈希函数之后可能会映射到相同的位置，因此如果一个不存在的元素对应的位位置都被其他元素所设置位1，则查询时就会误判
>
> ![哈希映射_误判.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/53823af248734ed694beca3362f0ec1c~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)
>
> 假设上图元素`3334`并没有加入集合，但是由于它映射的位置已经被其他元素所映射，则查询时会误判

### Count-Min Sketch 算法（近似计数器）

这个算法的技巧是：不存储所有的不同的元素，只存储它们Sketch的计数

- TinyLFU中把多个bit位看做一个整体,用于统计一个key的使用频率，该key是通过多次不同的哈希计算来映射多个不同的bit位,在读取时取映射地最小值作key的一个使用频率

- 在Caffeine中维护了一个4bit位的CountMinSketch用来记录key的使用频率，4-bit也就意味着统计的key最大使用频率为15


**CountMinSketch算法的流程**

- 选定n个hash函数，开一个 n x m 的二维整数数组作为哈希表
- 于每个元素，分别使用n个hash函数计算相应的哈希值，并对m取余，然后在对应的位置上增1，二维数组中的每个整数称为sketch
- 要查询某个元素的频率时，只需要取出n个sketch, 返回最小的那一个（其实n个sketch都是该元素的近似频率(>=真实频率)，返回任意一个都可以，该算法选择最小的那个）

![基础结构.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/4b07ab0d1bd1464588730d07817b4235~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

![哈希映射.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/a0db80ca3fed437cbc0c9042f9ee75ff~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

![哈希映射_误判.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/81ef96d0fa0d4deeb1aa00871601240c~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp)

+ 比如上图元素`123`映射到了元素`abc`第一行的相同位置，因此这个位置的计数累加了元素abc和元素123的计数和。但是只要我们取三行里面最小的一个计数，那么就能容忍这种情况。当然，如果一个元素的每一行的对应位置都被其他元素所映射，那么这个估算的计数就会比真实计数大

[CountMinSketch计数器：基于布隆过滤器思想的近似计数器](https://juejin.cn/post/7142896490061496334)

**算法评价**

- 只会估算偏大，永远不会偏小
- 只需要固定大小的内存和计算时间，和需要统计的元素多少无关
- 对于低频的元素，估算值相对的错误可能会很大

> **Count-Mean-Min Sketch**
>
> Count-Min Sketch算法对于低频的元素，结果不太准确，主要是因为hash冲突比较严重，产生了噪音，例如当m=20时，有1000个数hash到这个20桶，平均每个桶会收到50个数，这50个数的频率重叠在一块了。Count-Mean-Min Sketch 算法做了如下改进
>
> - 来了一个查询，按照 Count-Min Sketch的正常流程，取出它的d个sketch
> - 对于每个hash函数，估算出一个噪音，噪音等于该行所有整数(除了被查询的这个元素)的平均值
> - 用该行的sketch 减去该行的噪音，作为真正的sketch
> - 返回d个sketch的中位数

TinyLFU解决了LFU统计的内存消耗问题，和缓存保鲜的问题，但是TinyLFU是否还有缺点呢？

有，论文中是这么描述的，根据实测TinyLFU应对**突发的稀疏流量**时表现不佳。大概思考一下也可以得知，这些稀疏流量的访问频次不足以让他们在LFU缓存中占据位置，很快就又被淘汰了

而LRU对于稀疏流量效果很好，那可以不可以把LRU和LFU结合一下呢？就出现了下面这种缓存策略

## W-TinyLFU

### 整体架构

W-TinyLFU由多个部分组合而成，包括`窗口缓存`、`过滤器`和`主缓存`

主缓存是使用SLRU，元素刚进入W-TinyLFU会在窗口缓存暂留一会，被挤出窗口缓存时，会在过滤器中和主缓存中`最容易被淘汰的元素`进行PK，如果频率大于主缓存中这个`最容易被淘汰的元素`，才能进入主缓存

![W_TinyLFU.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e69c5cd0abee4d55b2bf23f138e82298~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

### 查询与写入

**查询**

- 记录访问频次，如果达到阈值，则触发保鲜机制（清空布隆过滤器，CountMin Sketch 访问减半），避免旧缓存长期驻留
- CountMin Sketch 对访问计数
- 在全局 hashMap（用于标记缓存存储区域） 中查询缓存是否存在，如果不存在则返回 false
- 根据缓存所在区域，进入对应的 s-lru 或 w-lru 中查询

**写入**

- 如果 w-lru 未满，则将数据写入后返回。如果满了，继续下一步
- 如果 s-lru 未满，则将数据写入后返回。如果满了，继续下一步
- 首先查找布隆过滤器，如果新 key 从未出现过，则不可能将老节点淘汰出去，此时在布隆过滤器中记录访问后返回
- 如果新 key 出现过，则此时在 CountMin Sketch 查询新 key 与 s-lru 的最后一个节点的访问频次。保留两者中访问频次最高的

### 窗口缓存

前面提到，W-TinyLFU选择一个元素是否加入缓存，得看这个元素加入缓存能否提高整体缓存的命中率，而这个评估的依据就是根据元素的频率。但是如果一个刚加入缓存的元素（表示元素刚刚才开始被访问），它的频率并不足以让它加入缓存，那么它会直接被淘汰。

因此在W-TinyLFU中使用LRU来作为一个`窗口缓存`，主要是让元素能够有机会在`窗口缓存`中去积累它的频率，避免因为频率很低而直接被淘汰。

窗口缓存很小，只占整个W-TinyLFU的1%

### 基于频率

在W-TinyLFU中主要是使用了LFU的访问频率的思想，根据访问的频率进行PK决定元素的去留，不过W-TinyLFU使用了另外的方式来统计元素的访问频率，也就是前面提到的BloomFilter和CountMinSketch

#### 频率统计机制

W-TinyLFU中使用BloomFilter+CountMinSketch来统计元素的访问频率，BloomFilter作为一个前置计数器，而CountMinSketch则作为主计数器。

BloomFilter避免前面所提到的稀疏流量对CountMinSketch计数器的影响，也就是稀疏流量只会在BloomFilter中进行计数（可以当成是最大值为1的计数），换句话说就是如果BloomFilter中没有计数则先把这次的计数加到BloomFilter中。

在W-TinyLFU中使用一个4bit大小的CountMinSketch计数器来统计每个元素的访问频率，它是主要的计数器，元素在第一个计数会记录在BloomFilter中，之后就会记录在CountMinSketch中。

需要BloomFilter的主要原因是CountMinSketch也是基于概率的，在计数的正确性一定的情况下，越多的元素进入CountMinSketch计数器，那么CountMinSketch就需要越大和越多的哈希函数。而BloomFilter可以帮忙抵挡那部分计数值还不需要那么大的元素（也就是计数值只有1），这样我们就可以减小CountMinSketch计数器的大小

![计数器.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/eba47b64775147429f744a3ac11aad0d~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)



估算元素计数值时需要把BloomFilter和CountMinSketch的计数进行求和，对于每个元素，BloomFilter最大只能表示计数值1，而CountMinSketch计数器4bit可以表达最大计数值15，因此每个元素最大能表达的计数值是16

#### 保鲜机制

前面提到了LFU建立起一定频率后就难以被淘汰，但是现实场景中访问频率是会随着时间变化的，因此W-TinyLFU加入了保鲜机制，来保证缓存中的元素是频繁被访问的。保鲜机制简单来说就是让每个元素的频率会随着时间降低，而不是一直保持不变。

具体做法很简单，我们会在进行一定次数的操作之后，把前面提到的BloomFilter和CountMinSketch计数器的计数值进行衰减。对于BloomFilter会直接清空（置0），而CountMinSketch则会把每个元素的计数除以二。

这样不仅可以让元素的频率随着时间降低，而且还避免BloomFilter和CountMinSketch长时间使用后被污染（因为这两个数据结构都是基于概率的，因此每个位置都可能映射多个元素，时间长了造成的污染会越来越大）。

### 主缓存

- 主缓存内部包含两个部分,Probation和Protected
- Probation用于存相对比较冷的数据,占用主缓存20%空间
- Protected用于存比较热的数据,它占用主缓存80%空间
- 数据可在这两部分空间里面相互转移

主缓存中的元素会被有效保护，除非主缓存中的最可能被淘汰的元素在过滤器PK时输给了从窗口缓存中淘汰的元素，才会有主缓存中的元素被淘汰

[W-TinyLFU缓存淘汰策略](https://juejin.cn/post/7144327955353698334)

# 常见的本地缓存

## caffeine

+ Caffeine是基于Java 1.8的高性能本地缓存库，由Guava改进而来，而且在Spring5开始的默认缓存实现就将Caffeine代替原来的Google Guava，官方说明指出，其缓存命中率已经接近最优值。实际上Caffeine这样的本地缓存和ConcurrentMap很像，即支持并发，并且支持O(1)时间复杂度的数据存取。二者的主要区别在于
  + ConcurrentMap将存储所有存入的数据，直到你显式将其移除；
  + Caffeine将通过给定的配置，自动移除“不常用”的数据，以保持内存的合理占用
  + 因此，一种更好的理解方式是：Cache是一种带有存储和移除策略的Map

### 使用

### 加载策略

Caffeine提供了四种缓存添加策略：手动加载，自动加载，手动异步加载和自动异步加载

#### 手动添加

```java
 public static void manualLoad() {
     Cache<String, String> cache = Caffeine.newBuilder()
             .expireAfterWrite(10, TimeUnit.MINUTES)
             .maximumSize(10_000)
             .build();
     //查找一个缓存元素，没有查找到的时候返回null
     String name = cache.getIfPresent("name");
     System.out.println("name:" + name);
     //查找缓存，如果缓存不存在则生成缓存元素,如果无法生成则返回null
     name = cache.get("name", k -> "小明");
     System.out.println("name:" + name);
     //添加或者更新一个缓存元素
     cache.put("address", "深圳");
     String address = cache.getIfPresent("address");
     System.out.println("address:" + address);
 }
```

#### 自动加载

```java
 private static void autoLoad() throws InterruptedException {
     LoadingCache<String, String> cache = Caffeine.newBuilder()
             .maximumSize(10_000)
             .expireAfterWrite(10, TimeUnit.MINUTES)
             .build(new CacheLoader<String, String>() {
                 @Nullable
                 @Override
                 public String load(@NonNull String s) throws Exception {
                     System.out.println("load:" + s);
                     return "小明";
                 }

                 @Override
                 public @NonNull Map<String, String> loadAll(@NonNull Iterable<? extends String> keys) throws Exception {
                     System.out.println("loadAll:" + keys);
                     Map<String, String> map = new HashMap<>();
                     map.put("phone", "13866668888");
                     map.put("address", "深圳");
                     return map;
                 }
             });
     //查找缓存，如果缓存不存在则生成缓存元素,如果无法生成则返回null
     String name = cache.get("name");
     System.out.println("name:" + name);
     //批量查找缓存，如果缓存不存在则生成缓存元素
     Map<String, String> graphs = cache.getAll(Arrays.asList("phone", "address"));
     System.out.println(graphs);
  }
```

#### 手动异步加载

```java
private static void manualAsynLoad() throws ExecutionException, InterruptedException {
   AsyncCache<String, String> cache = Caffeine.newBuilder()
          .expireAfterWrite(10, TimeUnit.MINUTES)
          .maximumSize(10_000)
          //可以用指定的线程池
          .executor(Executors.newSingleThreadExecutor())
          .buildAsync();
   //查找缓存元素，如果不存在，则异步生成
  CompletableFuture<String> graph = cache.get("name", new Function<String, String>() {
      @SneakyThrows
      @Override
      public String apply(String key) {
          System.out.println("key:" + key+",当前线程:"+Thread.currentThread().getName());
          //模仿从数据库获取值
          Thread.sleep(1000);
          return "小明";
      }
    });
  System.out.println("获取name之前_time:"+System.currentTimeMillis()/1000);
  String name = graph.get();
  System.out.println("获取name:"+name+",time:"+System.currentTimeMillis()/1000);
 }
```

#### 自动异步加载

```java
private static void autoAsynLoad() throws ExecutionException, InterruptedException {
    AsyncLoadingCache<String, String> cache = Caffeine.newBuilder()
           .maximumSize(10_000)
           .expireAfterWrite(10, TimeUnit.MINUTES)
           //你可以选择:去异步的封装一段同步操作来生成缓存元素
           .buildAsync(new AsyncCacheLoader<String, String>() {
               @Override
               public @NonNull CompletableFuture<String> asyncLoad(@NonNull String key, @NonNull Executor executor) {
                     System.out.println("自动异步加载_key:" + key+",当前线程:"+Thread.currentThread().getName());
                     return CompletableFuture.completedFuture("小明");
                 }
              });
           //也可以选择:构建一个异步缓存元素操作并返回一个future
           //.buildAsync((key, executor) -> createExpensiveGraphAsync(key, executor));
           //查找缓存元素，如果其不存在，将会异步进行生成
           cache.get("name").thenAccept(name->{
           System.out.println("name:" + name);
       });
    }

 private static CompletableFuture<String> createExpensiveGraphAsync(String key, Executor executor) {
     return CompletableFuture.supplyAsync(new Supplier<String>() {
         @Override
         public String get() {
             System.out.println(executor);
             System.out.println("key:" + key+",当前线程:"+Thread.currentThread().getName());
             return "小明";
         }
      }, executor);
}
```

### 回收策略

Caffeine提供了三种回收策略：基于容量回收、基于时间回收、基于引用回收

#### 基于容量回收策略

基于大小回收策略有两种：一种是基于容量大小，一种是基于权重大小。两者只能取其一。

##### 基于容量--maximumSize

为缓存容量指定特定的大小，Caffeine.maximumSize(long)。当缓存容量超过指定的大小，缓存将尝试逐出最近或经常未使用的条目

```java
public static void main(String[] args) throws InterruptedException {
   Cache<String, String> cache = Caffeine.newBuilder()
           .maximumSize(1)
           .removalListener((String key, Object value, RemovalCause cause) ->
                   System.out.printf("Key %s was removed (%s)%n", key, cause))
           .build();
   cache.put("name", "小明");
   System.out.println("name:" + cache.getIfPresent("name") + ",缓存容量:" + cache.estimatedSize());
   cache.put("address", "中国");
   Thread.sleep(2000);
   System.out.println("name:" + cache.getIfPresent("name") + ",缓存容量:" + cache.estimatedSize());
}
```

##### 基于权重--maximumWeight

用Caffeine.maximumWeight(long)指定权重大小，通过Caffeine.weigher(Weigher)方法自定义计算权重方式

```java
class Person{
        Integer age;
        String name;
}
public static void main(String[] args) throws InterruptedException {
   //初始化缓存，设置最大权重为20
   Cache<Integer, Integer> cache = Caffeine.newBuilder()
           .maximumWeight(20)
           .weigher((String key, Person value)-> value.getAge())
            .removalListener((Integer key, Object value, RemovalCause cause) ->
                    System.out.printf("Key %s was removed (%s)%n", key, cause))
            .build();

   cache.put(100, 10);
   //打印缓存个数，结果为1
   System.out.println(cache.estimatedSize());
   cache.put(200, 20);
   //稍微休眠一秒
   Thread.sleep(1000);
   //打印缓存个数，结果为1
   System.out.println(cache.estimatedSize());
}
```

#### 基于时间策略

##### 写入时间--expireAfterWrite

在最后一次写入开始计时，到达指定的时间后过期清除。如果一直写入，那么一直不会过期

```java
private static void writeFixedTime() throws InterruptedException {
   //在最后一次访问或者写入后开始计时，在指定的时间后过期。
   LoadingCache<String, String> graphs = Caffeine.newBuilder()
           .expireAfterWrite(1, TimeUnit.SECONDS)
           .removalListener((String key, Object value, RemovalCause cause) ->
                   System.out.printf("Key %s was removed (%s)%n", key, cause))
           .build(key -> createExpensiveGraph(key));
   String name = graphs.get("name");
   System.out.println("第一次获取name:" + name);
   name = graphs.get("name");
   System.out.println("第二次获取name:" + name);
   Thread.sleep(2000);
   name = graphs.get("name");
   System.out.println("第三次延迟2秒后获取name:" + name);
}
private static String createExpensiveGraph(String key) {
     System.out.println("重新自动加载数据");
     return "小明";
}
```

##### 写入和访问时间--expireAfterAccess

在最后一次写入或访问开始计时，在指定时间后过期清除。如果一直访问或写入，那么一直不会过期

```java
private static void accessFixedTime() throws InterruptedException {
   //在最后一次访问或者写入后开始计时，在指定的时间后过期。
  LoadingCache<String, String> graphs = Caffeine.newBuilder()
          .expireAfterAccess(3, TimeUnit.SECONDS)
          .removalListener((String key, Object value, RemovalCause cause) ->
                   System.out.printf("Key %s was removed (%s)%n", key, cause))
          .build(key -> createExpensiveGraph(key));
  String name = graphs.get("name");
  System.out.println("第一次获取name:" + name);
  name = graphs.get("name");
  System.out.println("第二次获取name:" + name);
  Thread.sleep(2000);
  name = graphs.get("name");
  System.out.println("第三次延迟2秒后获取name:" + name);
}

private static String createExpensiveGraph(String key) {
    System.out.println("重新自动加载数据");
    return "小明";
}
```

##### 自定义时间--expireAfter

自定义策略，由Expire实现独自计算时间。分别计算新增、更新、读取时间

```java
private static void customTime() throws InterruptedException {
    LoadingCache<String, String> graphs = Caffeine.newBuilder()
          .removalListener((String key, Object value, RemovalCause cause) ->
                  System.out.printf("Key %s was removed (%s)%n", key, cause))
          .expireAfter(new Expiry<String, String>() {
              @Override
              public long expireAfterCreate(@NonNull String key, @NonNull String value, long currentTime) {
                  //这里的currentTime由Ticker提供，默认情况下与系统时间无关，单位为纳秒
                  System.out.println(String.format("expireAfterCreate----key:%s,value:%s,currentTime:%d", key, value, currentTime));
                  return TimeUnit.SECONDS.toNanos(10);
              }

              @Override
              public long expireAfterUpdate(@NonNull String key, @NonNull String value, long currentTime, @NonNegative long currentDuration) {
                  //这里的currentTime由Ticker提供，默认情况下与系统时间无关，单位为纳秒
                  System.out.println(String.format("expireAfterUpdate----key:%s,value:%s,currentTime:%d,currentDuration:%d", key, value, currentTime,currentDuration));
                  return TimeUnit.SECONDS.toNanos(3);
              }

              @Override
              public long expireAfterRead(@NonNull String key, @NonNull String value, long currentTime, @NonNegative long currentDuration) {
                  //这里的currentTime由Ticker提供，默认情况下与系统时间无关，单位为纳秒
                  System.out.println(String.format("expireAfterRead----key:%s,value:%s,currentTime:%d,currentDuration:%d", key, value, currentTime,currentDuration));
                  return currentDuration;
               }
          })

          .build(key -> createExpensiveGraph(key));
    String name = graphs.get("name");
    System.out.println("第一次获取name:" + name);
    name = graphs.get("name");
    System.out.println("第二次获取name:" + name);
    Thread.sleep(5000);
    name = graphs.get("name");
    System.out.println("第三次延迟5秒后获取name:" + name);
    Thread.sleep(5000);
    name = graphs.get("name");
    System.out.println("第五次延迟5秒后获取name:" + name);
}
    
private static String createExpensiveGraph(String key) {
    System.out.println("重新自动加载数据");
    return "小明";
}
```

#### 基于引用策略

异步加载的方式不支持引用回收策略

##### 软引用

当GC并且内存不足时，会触发软引用回收策略

设置jvm启动时-XX:+PrintGCDetails -Xmx100m 参数，可以看GC日志打印会触发软引用的回收策略

```java
private static void softValues() throws InterruptedException {
    //当进行GC的时候进行驱逐
    LoadingCache<String, byte[]> cache = Caffeine.newBuilder()
           .softValues()
           .removalListener((String key, Object value, RemovalCause cause) ->
                   System.out.printf("Key %s was removed (%s)%n", key, cause))
           .build(key -> loadDB(key));
    System.out.println("1");
    cache.put("name1", new byte[1024 * 1024*50]);
    System.gc();
    System.out.println("2");
    Thread.sleep(5000);
    cache.put("name2", new byte[1024 * 1024*50]);
    System.gc();
    System.out.println("3");
    Thread.sleep(5000);
    cache.put("name3", new byte[1024 * 1024*50]);
    System.gc();
    System.out.println("4");
    Thread.sleep(5000);
    cache.put("name4", new byte[1024 * 1024*50]);
    System.gc();
    Thread.sleep(5000);
}

private static byte[] loadDB(String key) {
    System.out.println("重新自动加载数据");
    return new byte[1024*1024];
}
```

##### 弱引用

当GC时，会触发弱引用回收策略

设置jvm启动时-XX:+PrintGCDetails -Xmx100m 参数，可以看GC日志打印会触发弱引用的回收策略

```java
private static void weakKeys() throws InterruptedException {
    LoadingCache<String, byte[]> cache = Caffeine.newBuilder()
           .weakKeys()
           .weakValues()
           .removalListener((String key, Object value, RemovalCause cause) ->
                   System.out.printf("Key %s was removed (%s)%n", key, cause))
           .build(key -> loadDB(key));
    System.out.println("添加name1");
    cache.put("name1", new byte[1024 * 1024]);
    System.gc();
    System.out.println("添加name2");
    Thread.sleep(5000);
    cache.put("name2", new byte[1024 * 1024]);
    System.gc();
    System.out.println("添加name3");
    Thread.sleep(5000);
    cache.put("name3", new byte[1024 * 1024]);
    System.gc();
    Thread.sleep(5000);
}

private static byte[] loadDB(String key) {
    System.out.println("重新自动加载数据");
    return new byte[1024*1024];
}
```

## Guava Cache

Guava是Google团队开源的一款 Java 核心增强库，包含集合、并发原语、缓存、IO、反射等工具箱，性能和稳定性上都有保障，应用十分广泛。Guava Cache支持很多特性

- 支持最大容量限制
- 支持两种过期删除策略（插入时间和访问时间）
- 支持简单的统计功能
- 基于**LRU**算法实现

## Encache

Encache是一个纯Java的进程内缓存框架，具有快速、精干等特点，是Hibernate中默认的CacheProvider。同Caffeine和Guava Cache相比，Encache的功能更加丰富，扩展性更强

- 支持多种缓存淘汰算法，包括LRU、LFU和FIFO
- 缓存支持堆内存储、堆外存储、磁盘存储（支持持久化）三种
- 支持多种集群方案，解决数据共享问题

## 对比

- 从易用性角度，Guava Cache、Caffeine和Encache都有十分成熟的接入方案，使用简单。
- 从功能性角度，Guava Cache和Caffeine功能类似，都是只支持堆内缓存，Encache相比功能更为丰富
- 从性能上进行比较，Caffeine最优、GuavaCache次之，Encache最差

### 官方测试

+ Caffeine官方利用最权威的压测工具**「JMH」**对Caffeine、ConcurrentMap、GuavaCache、ehcache等做了详细的压测对比，结果如下

![在这里插入图片描述](https://img-blog.csdnimg.cn/af3a97203e5e46e1837e310a12818168.png?type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA6a2FTGVtb24=,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

### [使用JMH实际测试EhCache、GuavaCache和Caffeine之间的性能](https://blog.csdn.net/zj57356498318/article/details/102500131)

**测试代码**

基准测试的具体过程如下

- 预热阶段（Warmup Phase）
  在预热阶段，测试会进行3次迭代，每次迭代耗时5毫秒。这个阶段的目的是让JVM进行一些初始化工作，使缓存被加载到内存中并进行一些初始操作，以达到稳定的测试状态
- 正式测量阶段（Measurement Phase）
  在正式测量阶段，测试会进行5次迭代，每次迭代耗时1秒。每次迭代中，会调用`test()`方法，并记录方法的执行时间。通过这些迭代，可以获取更加准确的方法执行时间
- 并发线程数和JVM Fork
  基准测试中使用了8个并发线程（`@Threads(8)`），这意味着每个迭代中会有8个线程同时执行方法调用。此外，基准测试还通过`@Fork(3)`指定了进行3次fork，即在不同的JVM进程中运行测试。这样可以消除因垃圾回收等JVM因素对测试结果的影响
- 输出结果
  基准测试结果将以平均时间的微秒单位（`@OutputTimeUnit(TimeUnit.MICROSECONDS)`）输出，**ops**

- EhCache22

```java
@BenchmarkMode({Mode.AverageTime})
@OutputTimeUnit(TimeUnit.MICROSECONDS)
@Warmup(iterations=3, time = 5, timeUnit = TimeUnit.MILLISECONDS)
@Measurement(iterations=5,time = 1,timeUnit = TimeUnit.SECONDS)
@Threads(8)
@Fork(3)
@State(Scope.Thread)
public class EhCacheTest {
    private static CacheManager cacheManager = CacheManagerBuilder.newCacheManagerBuilder()
            .build(true);

    private static Cache<String, String> cache = cacheManager.createCache("myCache",
            CacheConfigurationBuilder.newCacheConfigurationBuilder(String.class, String.class,
                    ResourcePoolsBuilder.newResourcePoolsBuilder().heap(100, MemoryUnit.MB))
                    .withExpiry(ExpiryPolicyBuilder.timeToLiveExpiration(Duration.ofSeconds(1L))).build());

    static {
        cache.put("test","test");
    }
    @Benchmark
    public void test(){
        cache.get("test");
    }
}
```

- Guava Cache

```java
@BenchmarkMode({Mode.AverageTime})
@OutputTimeUnit(TimeUnit.MICROSECONDS)
@Warmup(iterations=3, time = 5, timeUnit = TimeUnit.MILLISECONDS)
@Measurement(iterations=5,time = 1,timeUnit = TimeUnit.SECONDS)
@Threads(8)
@Fork(3)
@State(Scope.Thread)
public class GuavaTest {
    private static Cache<String,String> cache = CacheBuilder.newBuilder()
            .maximumSize(100)
            .expireAfterWrite(1,TimeUnit.SECONDS)
            .build();

    static {
        cache.put("test","test");
    }

    @Benchmark
    public void test(){
        cache.getIfPresent("test");
    }
}
```

- Caffeine

```java
@BenchmarkMode({Mode.AverageTime})
@OutputTimeUnit(TimeUnit.MICROSECONDS)
@Warmup(iterations=3, time = 5, timeUnit = TimeUnit.MILLISECONDS)
@Measurement(iterations=5,time = 1,timeUnit = TimeUnit.SECONDS)
@Threads(8)
@Fork(3)
@State(Scope.Thread)
public class CaffeineTest {
    private static Cache<String,String> cache = Caffeine.newBuilder()
            .maximumSize(100)
            .expireAfterWrite(1,TimeUnit.SECONDS)
            .build();

    static {
        cache.put("test","test");
    }

    @Benchmark
    public void test(){
        cache.getIfPresent("test");
    }
}
```

**结果**

![在这里插入图片描述](https://img-blog.csdnimg.cn/20191011140815121.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pqNTczNTY0OTgzMTg=,size_16,color_FFFFFF,t_70)

- 奇特的地方
  - 在加过期时间的情况下三个缓存方案的性能均有所提升
  - Guava不加过期时间的情况下高并发会OOM
  - EhCache在加过期时间的情况下竟然比Guava的性能要好
  - Caffeine读比写的性能要高很多

**总结**

- Guava使用jdk的Queue记录缓存的写读情况，导致OOM；而Caffeine使用Disruptor的RingBuffer数据结构记录
- Caffeine对写的所有线程共用一个RingBuffer；而对读的每个线程维护一个RingBuffer

## caffine 本地缓存 和 currenthashmap 缓存

- Caffeine 缓存可以设定删除时间等删除条件、ConcurrentMap 代表的只[JAVA集合类](https://so.csdn.net/so/search?q=JAVA集合类&spm=1001.2101.3001.7020)等只能动态添加保存，除非显示的删除（有可能内存溢出）
- Caffeine 的读写能力显著高于ConcurrentHashMap 
