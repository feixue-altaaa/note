# 什么是集合以及使用的好处？

- 集合是用于存放对象的容器，而集合类是 Java 的一种数据结构，常用的集合类定义在 java.util 包中
- 需要注意的是，集合类只能存放对象，不能存放基本数据类型，且是对象的引用，而非对象本身

**好处**

- 提供高效的的数据结构和算法，挺高程序运行效率
- 提供通用 API 能力，降低开发和维护成本

> **为什么集合只能存放对象？**
>
> - 从源码上看的话，其底层存储数据的是一个Object[数组](https://so.csdn.net/so/search?q=数组&spm=1001.2101.3001.7020)，Object类型不能指代像int，double这样的基本类型，所以不能存储基本数据类型
> - Java中的泛型是通过编译时的类型擦除来完成的，当泛型被类型擦除后都变成Object类型。 但是Object不是基本类型的父类或基类，不能指代像int，double这样的基本类型，只能指代Integer，Double这样的引用类型。这里说不能指代不是指不能转换，(Object)1这种强制转换实际上是可行的，但是在理论上来说应该会报类型转换错误的，之所以没有报错是因为编译器做了处理：(Object)1 ->(Object)Integer.valueOf(1)，如果是基本类型那就转换成其包装类再强制转换成Object类型，所以实际上存放的还是引用类型，而不是基本类型
>
> **基本类型数据如何解决呢？**
>
> - 可以通过包装类把基本类型转为对象类型，存放引用就可以解决这个问题。更方便的，由于有了自动拆箱和装箱功能，基本数据类型和其对应对象(包装类)之间的转换变得很方便，想把基本数据类型存入集合中，直接存就可以了，系统会自动将其装箱成封装类，然后加入到集合当中

# Java中有哪些容器（集合类）？

Java中的集合类主要由Collection和Map这两个接口派生而出，其中Collection接口又派生出三个子接口，分别是Queue、 Set（无序不重复） 、 List（有序可重复）

- List 接口的实现类主要有：ArrayList、LinkedList、Stack 以及 Vector 等；

- Set 接口的实现类主要有：HashSet、TreeSet、LinkedHashSet等；

- Map 接口的实现类主要有：HashMap、TreeMap、Hashtable、ConcurrentHashMap 以及 Properties 

![在这里插入图片描述](https://raw.githubusercontent.com/feixue-altaaa/picture/master/pic/202307081328197.png)

> *注：紫色框体代表接口，其中加粗的是代表四类集合的接口。蓝色框体代表实现类，其中有阴影的是常用实现类*

# 数组和集合的区别

- 数组固定长度，集合长度可变；
- 数组可以存放基本数据类型，集合只能存储引用数据类型；
- 数组存储的元素必须是同一个数据类型，集合支持存储不同数据类型

# 介绍一下ArrayList的数据结构

**ArrayList的主要成员变量**

```java
private static final int DEFAULT_CAPACITY = 10;//数组默认初始容量
 
private static final Object[] EMPTY_ELEMENTDATA = {};//定义一个空的数组实例以供其他需要用到空数组的地方调用 
 
private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = {};//定义一个空数组，跟前面的区别就是这个空数组是用来判断ArrayList第一添加数据的时候要扩容多少。默认的构造器情况下返回这个空数组 
 
transient Object[] elementData;//数据存的地方它的容量就是这个数组的长度，同时只要是使用默认构造器（DEFAULTCAPACITY_EMPTY_ELEMENTDATA ）第一次添加数据的时候容量扩容为DEFAULT_CAPACITY = 10 
 
private int size;//当前数组的长度
```

**ArrayList的构造方法有三种**

![img](https://img-blog.csdn.net/20180530205624808?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3UwMTA4OTAzNTg=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

- ArrayList的底层是用**数组**来实现的，默认第一次插入元素时创建大小为**10**的数组，超出限制时会增加**50%**的容量，并且数据以 System.arraycopy() 复制到新的数组，因此最好能给出数组大小的预估值
- 按**数组下标访问元素**的性能很高，这是数组的基本优势。直接在数组末尾加入元素的性能也高，但如果按下标插入、删除元素，则要用 **System.arraycopy()** 来移动部分受影响的元素，性能就变差了，这是基本劣势

## ArrayList＜Integer＞如何转化为int[ ]数组

**for循环赋值**

**使用IntStream（java8新特性）**

```java
// 想要转换成int[]类型，就得先转成IntStream。
// 这里就通过mapToInt()把Stream<Integer>调用Integer::valueOf来转成IntStream
// 而IntStream中默认toArray()转成int[]。

int[] arr = list.stream().mapToInt(Integer::valueOf).toArray();
```

## ArrayList扩容机制

**先扩容后添加元素**

扩容是在我们通过add()添加元素时，发现数组满的时候进行扩容的，可以通过add()中看到

![image.png](https://p3-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/ccd10d63a9884d5bbb79af4bd364395f~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

`ensurExplicitCapacity` 判断是否需要进行扩容，

- 当我们要 add 进第 1 个元素到 ArrayList 时，elementData.length 为 0 （因为还是一个空的 list），因为执行了 `ensureCapacityInternal()` 方法 ，所以 minCapacity 此时为 10。此时，`minCapacity - elementData.length > 0`成立，所以会进入 `grow(minCapacity)` 方法。
- 当 add 第 2 个元素时，minCapacity 为 2，此时 e lementData.length(容量)在添加第一个元素后扩容成 10 了。此时，`minCapacity - elementData.length > 0` 不成立，所以不会进入 （执行）`grow(minCapacity)` 方法。
- 添加第 3、4···到第 10 个元素时，依然不会执行 grow 方法，数组容量都为 10。

直到添加第 11 个元素，minCapacity(为 11)比 elementData.length（为 10）要大。进入 grow 方法进行扩容。

很显然，`grow` 方法是扩容的关键

```java
     /**
     * 要分配的最大数组大小
     */
    private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;

    /**
     * ArrayList扩容的核心方法。
     */
    private void grow(int minCapacity) {
        // oldCapacity为旧容量，newCapacity为新容量
        int oldCapacity = elementData.length;
        //将oldCapacity 右移一位，其效果相当于oldCapacity /2，
        //我们知道位运算的速度远远快于整除运算，整句运算式的结果就是将新容量更新为旧容量的1.5倍，
        int newCapacity = oldCapacity + (oldCapacity >> 1);
        //然后检查新容量是否大于最小需要容量，若还是小于最小需要容量，那么就把最小需要容量当作数组的新容量，
        if (newCapacity - minCapacity < 0)
            newCapacity = minCapacity;
       // 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) `hugeCapacity()` 方法来比较 minCapacity 和 MAX_ARRAY_SIZE，
       //如果minCapacity大于最大容量，则新容量则为`Integer.MAX_VALUE`，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 `Integer.MAX_VALUE - 8`。
        if (newCapacity - MAX_ARRAY_SIZE > 0)
            newCapacity = hugeCapacity(minCapacity);
        // minCapacity is usually close to size, so this is a win:
        elementData = Arrays.copyOf(elementData, newCapacity);
    }
```

**int newCapacity = oldCapacity + (oldCapacity >> 1),所以 ArrayList 每次扩容之后容量都会变为原来的 1.5 倍左右（oldCapacity 为偶数就是 1.5 倍，否则是 1.5 倍左右）！**  奇偶不同，比如 ：10+10/2 = 15, 33+33/2=49。如果是奇数的话会丢掉小数

**结合例子看`grow()` 方法 ：**

- 当 add 第 1 个元素时，oldCapacity 为 0，经比较后第一个 if 判断成立，newCapacity = minCapacity(为 10)。但是第二个 if 判断不会成立，即 newCapacity 不比 MAX_ARRAY_SIZE 大，则不会进入 `hugeCapacity` 方法。数组容量为 10，add 方法中 return true,size 增为 1。
- 当 add 第 11 个元素进入 grow 方法时，newCapacity 为 15，比 minCapacity（为 11）大，第一个 if 判断不成立。新容量没有大于数组最大 size，不会进入 hugeCapacity 方法。数组容量扩为 15，add 方法中 return true,size 增为 1。
- 以此类推······

### hugeCapacity() 方法

从上面 `grow()` 方法源码我们知道： 如果新容量大于 MAX_ARRAY_SIZE,进入(执行) `hugeCapacity()` 方法来比较 minCapacity 和 MAX_ARRAY_SIZE，如果 minCapacity 大于最大容量，则新容量则为`Integer.MAX_VALUE`，否则，新容量大小则为 MAX_ARRAY_SIZE 即为 `Integer.MAX_VALUE - 8`

```java
  private static int hugeCapacity(int minCapacity) {
        if (minCapacity < 0) // overflow
            throw new OutOfMemoryError();
        //对minCapacity和MAX_ARRAY_SIZE进行比较
        //若minCapacity大，将Integer.MAX_VALUE作为新数组的大小
        //若MAX_ARRAY_SIZE大，将MAX_ARRAY_SIZE作为新数组的大小
        //MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8;
        return (minCapacity > MAX_ARRAY_SIZE) ?
            Integer.MAX_VALUE :
            MAX_ARRAY_SIZE;
```

### System.arraycopy() 和 Arrays.copyOf()方法

阅读源码的话，我们就会发现 ArrayList 中大量调用了这两个方法。比如：我们上面讲的扩容操作以及`add(int index, E element)`、`toArray()` 等方法中都用到了该方法！

#### System.arraycopy() 方法

源码

```java
   // 我们发现 arraycopy 是一个 native 方法,接下来我们解释一下各个参数的具体意义
    /**
    *   复制数组
    * @param src 源数组
    * @param srcPos 源数组中的起始位置
    * @param dest 目标数组
    * @param destPos 目标数组中的起始位置
    * @param length 要复制的数组元素的数量
    */
    public static native void arraycopy(Object src,  int  srcPos,
                                        Object dest, int destPos,
```

**运用场景**

```java
    /**
     * 在此列表中的指定位置插入指定的元素。
     *先调用 rangeCheckForAdd 对index进行界限检查；然后调用 ensureCapacityInternal 方法保证capacity足够大；
     *再将从index开始之后的所有成员后移一个位置；将element插入index位置；最后size加1。
     */
    public void add(int index, E element) {
        rangeCheckForAdd(index);

        ensureCapacityInternal(size + 1);  // Increments modCount!!
        //arraycopy()方法实现数组自己复制自己
        //elementData:源数组;index:源数组中的起始位置;elementData：目标数组；index + 1：目标数组中的起始位置； size - index：要复制的数组元素的数量；
        System.arraycopy(elementData, index, elementData, index + 1, size - index);
        elementData[index] = element;
        size++;
    }
```

先讲下 `add(int index, E element)` 这个方法的含义，就是在指定索引 index 处插入元素 element。比如说 `ArrayList.add(0, 30)`，意思就是在头部插入元素 30。

再来看看 `add` 方法的核心 `System.arraycopy`，这个方法有 5 个参数：

- elementData：源数组
- index：从源数组中的哪个位置开始复制
- elementData：目标数组
- index + 1：复制到目标数组中的哪个位置
- size - index：要复制的源数组中数组元素的数量

解释一下上面代码中 `arraycopy` 的意思，举个例子，我们想要在 index = 4 的位置插入元素，首先，我们会复制一遍源数组 elementData（这里我们称复制的数组为新数组吧），然后把源数组中从 index = 4 的位置开始到数组末尾的元素，放到新数组的 index + 1 = 5 的位置上

![image.png](https://p1-juejin.byteimg.com/tos-cn-i-k3u1fbpfcp/e4601c040fde4e62af6bda2938a0c1b6~tplv-k3u1fbpfcp-zoom-in-crop-mark:1512:0:0:0.awebp?)

#### Arrays.copyOf()方法

```java
    public static int[] copyOf(int[] original, int newLength) {
    	// 申请一个新的数组
        int[] copy = new int[newLength];
	// 调用System.arraycopy,将源数组中的数据进行拷贝,并返回新的数组
        System.arraycopy(original, 0, copy, 0,
                         Math.min(original.length, newLength));
        return copy;
    }
```

#### 两者的联系和区别

**联系**

看两者源代码可以发现 `copyOf()`内部实际调用了 `System.arraycopy()` 方法

**区别**

`arraycopy()` 需要目标数组，将原数组拷贝到你自己定义的数组里或者原数组，而且可以选择拷贝的起点和长度以及放入新数组中的位置 `copyOf()` 是系统自动在内部新建一个数组，并返回该数组

# ArrayList和LinkedList有什么区别？

- ArrayList 底层基于**动态数组**实现，LinkedList 底层基于**链表**实现

**访问效率的不同**

- 对于**按 index 索引数据**（get/set方法）：ArrayList 通过 index 直接定位到数组对应位置的节点，而 LinkedList需要从头结点或尾节点开始遍历，直到寻找到目标节点，因此在效率上 ArrayList 优于 LinkedList。

- 对于**随机插入和删除**：ArrayList 需要移动目标节点后面的节点（使用System.arraycopy 方法移动节点），而 LinkedList 只需修改目标节点前后节点的 next 或 prev 属性即可，因此在效率上 LinkedList 优于 ArrayList。

- 对于**顺序插入和删除**：由于 ArrayList 不需要移动节点，因此在效率上比 LinkedList 更好。这也是为什么在实际使用中 ArrayList 更多，因为大部分情况下我们的使用都是顺序插入

**利用效率的不同**

+ **ArrayList的容量是固定**的，当添加元素时，如果容量不够，就需要扩容，这会导致一定的性能损失。而**LinkedList没有容量限制**，可以动态添加元素

> **LinkedList的addLast方法和removeLast方法**
>
> LinkedList的addLast方法可以在链表的末尾添加一个元素，而removeLast方法可以从链表的末尾删除一个元素

# ArrayList 和 Vector 的区别？

**同步性不同**

+ Vector 是线程安全的，它的方法之间都加了 synchronized 关键字修饰，而 ArrayList 是非线程安全的。因此在不考虑线程安全情况下使用 ArrayList 的效率更高

**数据增长不同**

+ ArrayList 和 Vector 都有一个初始的容量大小，并在必要时对数组进行扩容。但 Vector 每次增长两倍，而 ArrayList 增长 1.5 倍

# 迭代器Iterator接口的作用及其使用

## **什么是迭代器**

- 迭代器： 可以被next()函数调用并不断返回下一个值的对象称之为迭代器(Iterator)
- 从另一种角度来定义迭代器就是：提供一种方法访问一个容器对象中各个元素，而又不需暴露该对象的内部细节。**迭代器模式，就是为容器而生**

## 迭代器的作用是什么？

- Iterator对象称为迭代器(设计模式的一种)，主要用于遍历Collection 集合中的元素
- 迭代是访问集合元素的一种方式,迭代器是一个能够记住遍历位置的对象，迭代器对象从集合的第一个元素开始访问,直到所有的元素都被访问完结束，如果想访问一个元素,需要把这个元素前面的所有元素都遍历后,才可以访问
- Collection集合接口继承了java.lang.Iterable接口，该接口有一个iterator()方法，那么所有实现了Collection接口的集合类都有一个iterator()方法，用以返回一个实现了Iterator接口的对象

## 使用for循环还是迭代器Iterator对比

- 采用ArrayList对随机访问比较快，而for循环中的get()方法，采用的即是随机访问的方法，因此在ArrayList里，for循环较快
- 采用LinkedList则是顺序访问比较快，iterator中的next()方法，采用的即是顺序访问的方法，因此在LinkedList里，使用iterator较快
- 从数据结构角度分析,**for循环适合访问顺序结构,可以根据下标快速获取指定元素.而Iterator 适合访问链式结构**,因为迭代器是通过next()和Pre()来定位的.可以访问没有顺序的集合

-  而**使用 Iterator 的好处在于可以使用相同方式去遍历集合中元素，而不用考虑集合类的内部实现**（只要它实现了 java.lang.Iterable 接口），如果使用 Iterator 来遍历集合中元素，一旦不再使用 List 转而使用 Set 来组织数据，那遍历元素的代码不用做任何修改，如果使用 for 来遍历，那所有遍历此集合的算法都得做相应调整,因为List有序,Set无序,结构不同,他们的访问算法也不一样

# 如何边遍历边删除集合中的元素？

+ 唯一正确的做法是使用迭代器 Iterator.remove() 方法

```java
Iterator<Integer> it=list.iterator();
while(it.hasNext()){
    it.remove();
}
```

+ 如果直接使用 foreach 循环遍历时删除时，该语法糖会自动生成一个 Iterator 进行遍历集合，但 Iterator 不允许遍历中的元素被修改，故会抛出 ConcurrentModificationException 异常

```java
for(Integer i : list){
    list.remove(I);
}
```

# Iterator 和 ListIterator 的区别？

**ListIterator 是一个继承于 Iterator 接口，功能更加强大的迭代器，但只能用于各种 List 类型的访问**

二者的主要区别

- Iterator 支持 List 和 Set，而 ListIterator 只支持 List；
- Iterator 只能单向访问，而 ListIterator 可以双向前后遍历；
- ListIterator 继承了 Iterator 的所有方法，并新增了如添加 add()、替换 set() 等更多好用方法

# 什么是 RandomAccess 接口？

- RandomAccess 接口是 Java 集合框架中为了标记 List 集合是否支持随机访问而设计
- 即只要 List 集合实现这个接口，就能支持快速随机访问，按位置读取元素的平均时间复杂度是 o(1)，如 ArrayList。而没有实现这个接口，表示不支持随机访问，如 LinkedList

- 通过源码和测试，我们可以发现：支持 RandomAccess 接口的集合使用 for 循环比使用迭代器 Iterator 更快，反之，不支持 RandomAccess 接口的集合使用 Iterator 或 foreach 更优

# 什么是 Fail-Fast 和 Fail-Safe？

- 在 Collection 集合类中，有线程安全和线程不安全这两大类型。对于线程不安全的类，并发情况下可能会出现快速失败（fail-fast） 情况，而线程安全的类，可能出现安全失败（fail-safe） 的情况
- 这里需要注意的是，以上情况都是针对并发而言


## fail-fast 机制

- 当遍历一个集合对象时，如果集合对象的结构被修改了，就会抛出 ConcurrentModificationExcetion 异常。但需要注意的是，迭代器的快速失败行为无法得到保证，因为一般来说，不可能对是否出现不同步并发修改做出任何硬性保证。快速失败迭代器则会尽最大努力抛出 ConcurrentModificationException
- 我们以 ArrayList 为例，ArrayList 继承自 AbstractList 类，AbstractList 内部有一个 modCount 属性，代表修改的次数。且每一次 add、remove 操作都会使得 modCount 自增

```java
public boolean add(E e) {
    modCount++;  // here
    add(e, elementData, size);
    return true;
}
```

+ 迭代器对象有一个属性 expectedModCount 属性，它被赋值为该方法调用时 modCount 值。这也就意味着 expectedModCount 是 modCount 在这个时间点的快照值，且这个值在 iterator 内部是不会再发送变化的

```java
private class Itr implements Iterator<E> {
    int cursor = 0;  // Index of next elemnet to be returned.
    int lastRet = -1;  // Index of last elemnet returned.
    int expectedModCount = modCount;
}
```

+ 我们在使用迭代器调用 next() 方法时，第一步就是检查 modCount 和 expectedModCount 是否相等，如果不相等就立即抛出 ConcurrentModificationException。到这就很好理解了，如果我们使用迭代器的同时使用 add、remove 操作了集合，则会导致 modCount 发生变化，从而导致抛出异常

```java
public E next() {
    checkForComodification();
    // ......
}

final void checkForComodification() {
    if (modCount != expectedModCount)
        throw new ConcurrentModificationException();
}
```

- 至于为什么快速失败行为无法得到保证也就不难理解，因为虽然集合发生了变化，但如果没有调用 next() 方法，则也不会抛出异常

- 即**这个机制的主要目的是告诉你，当前迭代器要进行操作是有问题的，因为集合对象现在的状态发生了改变**

- 那没为何使用迭代器 remove() 方法不会触发该机制？

- 通过源码不难看出，remove() 方法没有进行 modCount 的检查，并手动把 expectedModCount 值修改成了 modCount，这又保证了下一次迭代的正确

## fail-safe 机制

- Fail-Safe 机制主要是针对线程安全的集合类（如 ConcurrentHashMap），其的出现的目的是为了解决 fail-fast 抛出异常处理起来不方便的问题
- 并发容器的 iterator() 方法返回的迭代器内部都是保存了该集合对象的一个快照副本，并且没有 modCount 等数值做检查。这也造成了并发容器迭代器读取的数据是某个时间点的快照版本。你可以并发读取，不会抛出异常，但无法不保证遍历读取的值和当前集合对象的状态是一致的。 同时创建集合拷贝还需要时间和空间上的额外开销

# HashMap

## 实现

- HashMap继承了AbstractMap类，实现了Map，Cloneable，Serializable接口
- HashMap的容量，默认是16
- HashMap的加载因子，默认是0.75，当HashMap中元素数超过容量*加载因子时，HashMap会进行扩容

HashMap类中的元素是Node类，是定义在HashMap中的一个内部类，实现了Map.Entry接口。Node类的定义如下

```java
    /**
     * Basic hash bin node, used for most entries.  (See below for
     * TreeNode subclass, and in LinkedHashMap for its Entry subclass.)
     */
    static class Node<K,V> implements Map.Entry<K,V> {
        final int hash;
        final K key;
        V value;
        Node<K,V> next;
 
        Node(int hash, K key, V value, Node<K,V> next) {
            this.hash = hash;
            this.key = key;
            this.value = value;
            this.next = next;
        }
 
        public final K getKey()        { return key; }
        public final V getValue()      { return value; }
        public final String toString() { return key + "=" + value; }
 
        public final int hashCode() {
            return Objects.hashCode(key) ^ Objects.hashCode(value);
        }
 
        public final V setValue(V newValue) {
            V oldValue = value;
            value = newValue;
            return oldValue;
        }
 
        public final boolean equals(Object o) {
            if (o == this)
                return true;
            if (o instanceof Map.Entry) {
                Map.Entry<?,?> e = (Map.Entry<?,?>)o;
                if (Objects.equals(key, e.getKey()) &&
                    Objects.equals(value, e.getValue()))
                    return true;
            }
            return false;
        }
    }
```

+ HashMap使用拉链法管理其中的每个节点。由Node节点组成链表之后，HashMap定义了一个Node数组

```java
transient Node<K,V>[] table;
```

+ 这个数组记录了每个链表的第一个节点，于是最终形成了HashMap下面这样的数据结构

![img](https://raw.githubusercontent.com/feixue-altaaa/picture/master/pic/202307081735996.jpeg)

## 底层数据结构是什么？

- 在 JDK 1.7 中，HashMap 底层使用数组+链表的形式进行存储，在 JDK 1.8 之后，增加了红黑树，即数组+链表+红黑树的形式存储元素
- 其中桶数组是用来存储元素，链表是用来解决哈希冲突，而红黑树是用来提高查询效率的

## 解决Hash冲突的方法

### 链地址法

- 在hash值为k的元素对应的地址上建立一个链表，然后将所有hash值为K的元素都放在此链表上
  - 优点：因为是链表这种数据结构所有增删快
  - 缺点：查询慢
- 在Java1.7以及之前都采用的是链地址法来解决HashMap中的hash冲突
- 在java1.8之后当链表长度大于8，且总数据量大于64的时候，链表就会转化成红黑树

### 再哈希法

- 使用多个hash函数 当一个函数产生冲突的时候再使用下一个函数再此进行Hash求值如果还产生冲突则再使用下一个函数直到不再产生冲突为止
- Hi=RHi(key) i=1,2,3,4,…n

### 建立公共溢出区

- 将hash表分成两部分基本表和溢出表凡是和基本表中元素产生Hash冲突的元素一律放入溢出表

## 链表和红黑树之间的转换？

- 链表长度大于 8 且数组长度大于 64，则将链表转换成红黑树；
- 链表长度小于 6 时会将红黑树转换成链表

## 阈值为何是 8 和 6？

- 作者在源码中注释到：TreeNodes 占用空间是普通 Nodes 的两倍， 所以只有当普通桶包含足够多的节点时才会转成 TreeNodes
- 当 hashCode 离散性足够好时，树型桶用到的概率非常小，因为数据均匀分布在每个桶中，几乎不会有链表长度会达到阈值。但是在随机 hashCode 情况下，离散性可能会变差，然而又不能阻止用户使用这种不好的 hash 算法，因此就可能导致不均匀的数据分布。不过理想情况下随机 hashCode 算法下所有桶中节点的分布频率会遵循泊松分布，作者还计算出相关概率，即当链表长度达到 8 个元素的概率为 0.00000006，几乎是不可能事件
- 因此，源码定义了在 binCount>=7（从 0 开始共 8 个数），**即该槽插入第 9 个节点（超过 8 个）时转为红黑树**
- 至于为何树转链表的阈值选为 6？主要还是为了避免红黑树和链表之间频繁转换带来的性能损耗

## 为何使用红黑树而非二叉树或平衡树？

- 相比普通二叉树，红黑树是一棵平衡树，它的添加、删除和查找操作最差时间复杂度为 o(logn)，避免了普通二叉树最差情况下 o(n) 的复杂度。
- 平衡二叉树是比红黑树更加严格的平衡树，为了达到平衡需要进行更多的旋转次数，所以红黑树插入删除操作效率更高

## put 操作的执行流程？

```java
final V putVal(int hash, K key, V value, boolean onlyIfAbsent,
                   boolean evict) {
        Node<K,V>[] tab; Node<K,V> p; int n, i;
        if ((tab = table) == null || (n = tab.length) == 0)
            n = (tab = resize()).length;
        if ((p = tab[i = (n - 1) & hash]) == null)
            tab[i] = newNode(hash, key, value, null);
        else {
            Node<K,V> e; K k;
            if (p.hash == hash &&
                ((k = p.key) == key || (key != null && key.equals(k))))
                e = p;
            else if (p instanceof TreeNode)
                e = ((TreeNode<K,V>)p).putTreeVal(this, tab, hash, key, value);
            else {
                for (int binCount = 0; ; ++binCount) {
                    if ((e = p.next) == null) {
                        p.next = newNode(hash, key, value, null);
                        if (binCount >= TREEIFY_THRESHOLD - 1) // -1 for 1st
                            treeifyBin(tab, hash);
                        break;
                    }
                    if (e.hash == hash &&
                        ((k = e.key) == key || (key != null && key.equals(k))))
                        break;
                    p = e;
                }
            }
            if (e != null) { // existing mapping for key
                V oldValue = e.value;
                if (!onlyIfAbsent || oldValue == null)
                    e.value = value;
                afterNodeAccess(e);
                return oldValue;
            }
        }
        ++modCount;
        if (++size > threshold)
            resize();
        afterNodeInsertion(evict);
        return null;
    }
```

- 首先通过 hash() 函数方法计算出 key 的 hash 值；

- 判断桶数组是否为空或长度为 0，是则使用 resize() 方法进行初始化；

- 根据 tab[i = (n - 1) & hash] （n 是数组长度）计算 key 在数组中对应的下标值，如果该位置没有存放数据，则使用 newNode() 方法直接插入当前数据；

- 如果对应下标已存在数据，则需要分三种情况处理碰撞

  - 对应数组当前 node 节点与新元素 hash 值相等，且 key 值也相等，则使用新元素 value 值覆盖旧值；
  - 对应数组当前 node 节点是树型节点，则将新元素直接插入红黑树中；
  - 对应数组当前 node 节点是链表节点，则遍历此链表到尾部，并将新元素插入到链表尾部。插入成功之后再根据链表长度与树化阈值的比较判断是否需要进行树化；
- 最后在所有元素处理完毕后，还需判断当前元素大小是否超过扩容阈值，超过则调用 resize() 方法扩容

## hash 值如何计算？

```
static final int hash(Object key) {
    int h;
    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
```

+ 当 key 为 null 时 hash 值为 0，否则，hash 值就是 key 的 hashCode 值异或 key 的 hashCode 无符号右移 16 位的结果。即 hash 值是 hashCode 值的高 16 位和低 16 位的异或结果。通过异或处理，避免了只靠低位数据计算 hash 值时导致的冲突，计算结果由高低位共同决定，可以使元素分布更均匀

## 常用的 Hash 函数？

**除留余数法**

+ 也是 HashMap 中使用的方法，计算公式为 H(key) = key % p (p<=n)，关键字除以一个不大于哈希表长度的正整数 p，所得余数为地址

**直接定址法**

+ 直接根据 key 映射到对应哈希表位置，如 i 就直接放到下标 i 的位置

**数字分析法**

+ 根据 key 的某些数字（如十位或者百位）作为映射的位置

**平方取中法**

+ 根据 key 平方的中间几位作为映射的位置

**折叠法**

+ 把 key 分割成位数相同的几段，然后将其叠加和作为映射的位置

## HashMap 容量为何是 2 的倍数？

- 为了方便哈希取余，因为当除数是 2 的倍数时，可以将 % 取模运算将换成 & 位运算，以达到更高的运算效率

- 扩容后容量也是 2 的倍数，则每个桶中的节点要么保留在当前位置，要么移动 2 次幂的位置（即 原位置+原数组容量），这样就可以快速简洁的完成数据迁移

- 减少位运算带来的哈希冲突
  - 最简单的映射算法就是取模 `hash%length`，但**取模效率不如位运算效率高**，所以使用位运算求索引位置 `hash&(length-1)`
  - 为了减少位运算带来的哈希冲突，将数组长度控制为`2^n`，这样hash值始终在和一个大部分数字都为1的值做与运算，那么就有**更大的可能性不会发生冲突**
  - 2的n次方实际就是1后面n个0，2的n次方-1  实际就是n个1
  - 因为在与运算中，如果一个数全为1，那么结果完全取决于另一个数，而这里的另一个数就是指hash算法求出的hash值（唯一），这样就大大减少了冲突可能性
  - 想像一个极限情况：数组无限大，并且全为1，那么就一定不会发生冲突，因为hash值都不相同


## 为何负载因子是 0.75？

- 为了减少哈希冲突发生的概率，当 HashMap 中的元素个数达到一个阈值 threshold 的时候就会触发扩容，把所有元素 rehash 之后再放在扩容后的容器中，这是一个相当耗时的操作
- 这个阈值 threshold 又与**当前元素个数（newCap）以及负载因子（loadFactor）**正相关。至于为何选址 0.75 作为负载因子，简单来讲这是出于对时间和空间成本综合考量

  - 如果我们设的负载因子比较大，元素比较多时，扩容时桶数组没有发生碰撞的位置较少，查找的时间成本就增加

  - 如果设置的比较小，元素又比较少时，数组还有足够空位的时候就发生了扩容，发生哈希碰撞的概率就降低了，查找时间成本降低，但是就需要更多的空间去存储元素，空间成本就增加

+ **负载因子是0.75的时，空间利用率比较高，而且避免了相当多的Hash冲突，使得底层的链表或者是红黑树的高度比较低，提升了空间和时间效率**

## HashMap 什么时候扩容，如何进行扩容的？

### 什么时候扩容

**初始化后放入元素时**

+ 创建对象以后，HashMap并不是立即初始化table，而是在第一次放入元素时，才会初始化table，这很HashMap节省内存得一种机制，而table的初始化其实是resize方法实现的

**达到阈值时**

+ 所谓阈值，就是HashMap中threshold这个属性，阈值的计算方式很简单，基本上就是capacity（table容量） * loadFactor（负载因子），这里我觉得capacity应该称为理论容量，是因为正常情况下达到阈值就扩容了，达到阈值时HashMap认为哈希冲突的次数会不能接受，因此需要扩容

### 如何进行扩容（JDK1.8）

**初始化**

- 初始化已完成的正常扩容逻辑：**table容量和阈值都扩大2倍**
- 指定大小的初始化逻辑：**算出大于等于指定初始化容量的最小2的次幂，作为table容量**
- 未指定大小的初始化逻辑：**默认table容量16，阈值为16 \* 0.75 = 12**

**扩容**

+ 扩容时不需要rehash

+ 首先假设原本有几个key，他们的的[hash](https://so.csdn.net/so/search?q=hash&spm=1001.2101.3001.7020)值为

  | key  | hash值 | 下标 hash &  (length-1) |
  | :--: | :----: | :---------------------: |
  | key1 |  101   |      00000101 = 5       |
  | key2 | 10101  |      00000101 = 5       |
  | key3 | 100101 |      00000101 = 5       |
  | key4 | 110101 |      00000101 = 5       |

+ 而假设原本table容量 **oldCap = 16;**那么这几个key都会存储在`table[5]`位置，如下图

+ ![在这里插入图片描述](https://raw.githubusercontent.com/feixue-altaaa/picture/master/pic/202307091106831.png)

+ 当进行扩容时，容量扩大一倍也就是newCap = 32,此时table.length -1 = 31；就会出现两种情况key1 和 key3 的下标还是5 （0000 0101）；key2 和 key4 的下标变为了 21 (0001 0101)

  | key  | hash值 | 下标 hash &  (length-1) |
  | :--: | :----: | :---------------------: |
  | key1 |  101   |      00000101 = 5       |
  | key2 | 10101  |      00001101 = 21      |
  | key3 | 100101 |      00000101 = 5       |
  | key4 | 110101 |      00001101 = 21      |

+ `resize`方法里的`lo列表和hi列表`，**其实就是看key高一位的哈希值是1还是0，来决定是放到哪个队列里。** 移位后的HashMap如下图

![在这里插入图片描述](https://raw.githubusercontent.com/feixue-altaaa/picture/master/pic/202307091109490.png)

+ 这里`HashMap`非常精妙的实现了扩容，**没有重新计算对象的哈希值，甚至连下标的重新计算也只需要进行一位相与的计算（hash高位 & newCap-1 )**
+ ![在这里插入图片描述](https://img-blog.csdnimg.cn/b2a153d179d74bfd9b9fd3316031e1bc.png#pic_center)

## JDK 1.8 中有哪些优化？

**数据结构**

+ 将原来数组+链表改成了数组+链表或红黑树的结构，用于降低查找操作的时间复杂度

**插入方式**

+ put 操作链表的插入方式从头插法改成了尾插法，简单说法就是 1.7 将新元素直接放到链表头部，而 1.8 插入到链表尾部。这是因为头插法扩容时会使链表发生反转，多线程环境下会产生环

> # HashMap链表成环的原因
>
> **成环的时机**
>
> - HashMap 扩容时
> - 多线程环境下
>
> [HashMap链表成环的原因和解决方案](https://blog.csdn.net/fengyuyeguirenenen/article/details/122760014)
>
> 比如有两个线程同时对该HashMap进行rehash，要将链表进行重新排列
> rehash前链表结构为：A --> B -->C
>
> ![在这里插入图片描述](https://img-blog.csdnimg.cn/852e9ddfbe2c4cf495625523273cbae2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5pyJ5pe25YCZ5oiR5Lmf5Lya,size_12,color_FFFFFF,t_70,g_se,x_16)
>
> 线程1进行操作：遍历原链表，首先获得节点A及A.next = B，操作挂起，线程2进入。（线程1仅获取到了数据A及next，并未进行其他操作）
>
> ![在这里插入图片描述](https://img-blog.csdnimg.cn/25721204ff3244c593a322e7df992f1c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5pyJ5pe25YCZ5oiR5Lmf5Lya,size_11,color_FFFFFF,t_70,g_se,x_16)
>
> 线程2进行操作：遍历原链表，以头插方式遍历执行，执行完成 B – > A
>
> ![在这里插入图片描述](https://img-blog.csdnimg.cn/ec55fb0f32274e9a808fb38219d33180.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5pyJ5pe25YCZ5oiR5Lmf5Lya,size_18,color_FFFFFF,t_70,g_se,x_16)
>
> 线程1继续执行：遍历原链表，头插方式执行，完成 B – > A，此时线程2数据提交，线程1发现 B.next 不为null，继续遍历执行，又将B.next = A插入，形成A --> B – > A循环结构

**reHash**

+ 扩容时 1.7 需要对数组中所有节点重新 hash 计算在新数组中的位置，而 1.8 采用了更简单的位运算方式，提高扩容的效率

**扩容时机**

+ 1.7 在插入时会先判断是否需要扩容，再插入，而 1.8 会先进行插入，再判断是否需要扩容

**hash函数**

+ 1.7 做了四次移位和四次异或，而 1.8 只需要一次。因为 4 次的边际效用也不大，改为一次可提升效率

## HashMap 是否线程安全以及如何解决？

**HashMap 是非线程安全**的，可能会发生这些问题

- 多线程下扩容死循环。由 JDK 1.7 的头插法导致，1.8 中以解决
- 多线程的 put 可能导致元素的丢失
  + 如果两个线程计算出来的索引位置是相同的，那会造成前一个 key 被后一个 key 覆盖，从而导致前一个元素的丢失

+ put 和 get 并发时，可能导致 get 为 null
  + 线程 1 执行 put 时，因为元素个数超出 threshold 而导致 rehash，线程 2 此时执行 get，有可能导致这个问题。这个问题在 JDK 1.7 和 JDK 1.8 中都存在

**如何解决 HashMap 非线程安全问题**

- 我们可以使用 Java 中线程安全的 Map，如 HashTable、Collections.SynchronizedMap 以及 ConcurrentHashMap 等
- HashTable 是直接在操作方法上加 synchronized 关键字，锁住整个table数组，粒度比较大
- Collections.SynchronizedMap 是使用 Collections 集合工具的内部类，通过传入 Map 封装出一个 SynchronizedMap 对象，内部定义了一个对象锁，方法内通过对象锁实现

## HashMap 节点是否有序？

+ HashMap 是无序的，根据 hash 值随机插入。如果想使用有序的 Map，可以使用 LinkedHashMap 或者 TreeMap

# ConcurrentHashMap

## 常见方法

### **putIfAbsent(a,b)**

**putIfAbsent方法主要是在向ConcurrentHashMap中添加键—值对的时候，它会先判断该键值对是否已经存在**

- 如果不存在（新的entry），那么会向map中添加该键值对，并返回null
- 如果已经存在，那么不会覆盖已有的值，直接返回已经存在的值

```java
#xxl-job源码示例
if (cost > 500) {       // ob-timeout threshold 500ms
                    AtomicInteger timeoutCount = jobTimeoutCountMap.putIfAbsent(jobId, new AtomicInteger(1));
                    if (timeoutCount != null) {
                        timeoutCount.incrementAndGet();
                    }
                }
```

## ConcurrentHashMap 底层实现

### JDK1.7

底层数据结构：Segments数组+HashEntry数组+链表，采用**分段锁**保证安全性

**容器中有多把锁，每一把锁锁一段数据，这样在多线程访问时不同段的数据时，就不会存在锁竞争了，这 样便可以有效地提高并发效率。这就是ConcurrentHashMap所采用的”分段锁”思想**

![在这里插入图片描述](https://img-blog.csdnimg.cn/1fbe63ca461c4af591036dd9ce364a14.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAY3blsZXnpLo=,size_20,color_FFFFFF,t_70,g_se,x_16)

- 一个ConcurrentHashMap中有一个Segments数组，一个Segments中存储一个HashEntry数组，每个HashEntry是一个链表结构的元素

- segment继承自ReentrantLock锁。 首先将数据分为一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一段数据时，其他段的数据也能被其他线程访问，实现了真正的并发访问

- 可以通过构造函数指定,数组扩容不会影响其他的segment,get无需加锁,volatile保证内存可见性

#### **get()操作**

**HashEntry中的value属性和next指针是用volatile修饰的，保证了可见性，所以每次获取的都是最新值，get过程不需要加锁**

- 1.将key传入get方法中，先根据key的hashcode的值找到对应的segment段。
- 2.再根据segment中的get方法再次hash，找到HashEntry数组中的位置。

- 3.最后在链表中根据hash值和equals方法进行查找。

ConcurrentHashMap的get操作跟HashMap类似，只是ConcurrentHashMap第一次需要经过一次hash定位到Segment的位置，然后再hash定位到指定的HashEntry，遍历该HashEntry下的链表进行对比，成功就返回，不成功就返回null

#### put()操作

- 1.将key传入put方法中，先根据key的hashcode的值找到对应的segment段
- 2.再根据segment中的put方法，加锁lock()。
- 3.再次hash确定存放的hashEntry数组中的位置

- 4.在链表中根据hash值和equals方法进行比较，如果相同就直接覆盖，如果不同就插入在链表中

### JDK1.8

**底层数据结构：Synchronized + CAS +Node +红黑树.Node的val和next都用volatile保证,保证可见性,查找,替换,赋值操作都使用CAS**

> 为什么在有Synchronized 的情况下还要使用CAS
>
> 因为CAS是乐观锁,在一些场景中(并发不激烈的情况下)它比Synchronized和ReentrentLock的效率要高,当CAS保障不了线程安全的情况下(扩容或者hash冲突的情况下)转成Synchronized 来保证线程安全,大大提高了低并发下的性能

锁 : 锁是锁的链表的head的节点,不影响其他元素的读写,锁粒度更细,效率更高,扩容时,阻塞所有的读写操作(因为扩容的时候使用的是Synchronized锁,锁全表),并发扩容

#### get()操作

get操作全程无锁。get操作可以无锁是由于Node元素的val和指针next是用volatile修饰的。

在多线程环境下线程A修改节点的val或者新增节点的时候是对线程B可见的。

1.计算hash值，定位到Node数组中的位置

2.如果该位置为null，则直接返回null

3.如果该位置不为null，再判断该节点是红黑树节点还是链表节点

如果是红黑树节点，使用红黑树的查找方式来进行查找

如果是链表节点，遍历链表进行查找

#### put()操作

- 先判断Node数组有没有初始化，如果没有初始化先初始化initTable();
- 根据key的进行hash操作，找到Node数组中的位置，如果不存在hash冲突，即该位置是null，直接用CAS插入
- 如果存在hash冲突，就先对链表的头节点或者红黑树的头节点加synchronized锁

- 如果是链表，就遍历链表，如果key相同就执行覆盖操作，如果不同就将元素插入到链表的尾部， 并且在链表长度大于8， Node数组的长度超过64时，会将链表的转化为红黑树
- 如果是红黑树，就按照红黑树的结构进行插入

## 为什么使用 Synchronized 替换 ReentrantLock?

- Segment继承了ReentrantLock，所以Segment是一种可重入锁，Segment可重入锁锁住的是一个HashEntry数组，**synchronized锁住的只是发生hash冲突的链表的头节点或红黑树的节点，提高了并发性能**
- 从JDK1.6开始，对 synchronized 锁的实现引入了大量的优化，并且 synchronized 有多种锁状态，会从**偏向锁 -> 轻量级锁 -> 重量级锁**一步步转换，只要并发的线程可以在一定次数的自旋内拿到锁（偏向锁不用自旋），那么synchronized就不会升级为重量级锁，等待的线程也不会被挂起，减少了线程挂起和唤醒的切换的过程开销，而ReentrantLock不会自旋，会直接挂起，这样一来就很容易会多出线程上下文开销的代价
- 减少内存开销 。假设使用可重入锁来获得同步支持，那么每个节点都需要通过继承 AQS 来获得同步支持。但并不是每个节点都需要获得同步支持的，只有链表的头节点（红黑树的根节点）需要同步，这无疑带来了巨大内存浪费

[ConcurrentHashMap原理详解](https://blog.csdn.net/qq_42068856/article/details/126091526)

## Key 和 Value 不支持 null 的原因？

+ 我们先说 为何 value 不能为 null。因为 ConcurrentHashMap 是用于多线程的，如果 get(key) 方法到了 null，就无法判断存在的 value 是 null，还是没有找到对应的 key 而为 null，就有了二义性

## size 方法如何计算大小？

**1.7**

- 虽然 count 变量是被 volatile 修饰的，但是并不是简单的把所有 Segment 的 count 值相加。因为有可能在累加过程中 count 值发生了改变，那么此时结果就不正确了。但是也不能直接锁住，这样效率太低。因此在 JDK1.7 中的做法是先尝试 2 次通过不锁住 Segment 的方式来统计各个 Segment 大小，如果统计的过程中，容器的 count 发生了变化，则再采用加锁的方式来统计所有Segment 的大小
- 那么 ConcurrentHashMap 是如何判断在统计的时候容器是否发生了变化呢？

- 使用 modCount 变量，在 put、remove 方法里操作元素前都会将变量 modCount++，那么在统计大小前后比较 modCount 是否发生变化，从而得知容器的大小是否发生变化


**1.8**

- 由于没有 segment 的概念，所以只需要用一个 baseCount 变量来记录 ConcurrentHashMap 当前节点的个数
- 先尝试通过CAS 更新 baseCount 计数

- 如果多线程竞争激烈，某些线程 CAS 失败，那就 CAS 尝试将 cellsBusy 置 1，成功则可以把 baseCount 变化的次数暂存到一个数组 counterCells 里，后续数组 counterCells 的值会加到 baseCount 中

- 如果 cellsBusy 置 1 失败又会反复进行 CAS baseCount 和 CAS counterCells 数组

# LinkedHashMap 如何实现有序？

+ LinkedHashMap 维护了一个双向链表以及头尾两节点，同时 LinkedHashMap 节点 Entry 内部除了继承 HashMap 的 Node 属性，还有 before 和 after 用于标识前置节点和后置节点

# TreeMap 如何实现有序？

+ TreeMap 是按照 Key 的自然顺序或者 Comprator 的顺序进行排序，内部是通过红黑树来实现。所以要么 key 所属的类实现 Comparable 接口，或者自定义一个实现了 Comparator 接口的比较器，传给 TreeMap 用于 key 的比较

# Java双端队列Deque

[Deque](https://so.csdn.net/so/search?q=Deque&spm=1001.2101.3001.7020)是一个双端队列接口，继承自Queue接口，Deque的实现类是LinkedList、ArrayDeque、LinkedBlockingDeque，其中LinkedList是最常用的

Deque有三种用途

- 普通队列(一端进另一端出)
  - Queue queue = new LinkedList()或Deque deque = new LinkedList()
- 双端队列(两端都可进出)
  - Deque deque = new LinkedList()
- 堆栈
  - Deque deque = new LinkedList()

> 注意：Java堆栈[Stack类](https://so.csdn.net/so/search?q=Stack类&spm=1001.2101.3001.7020)已经过时，Java官方推荐使用Deque替代Stack使用。Deque堆栈操作方法：push()、pop()、peek()

Deque是一个线性collection，支持在两端插入和移除元素。名称 deque 是“double ended queue（双端队列）”的缩写，通常读为“deck”。大多数 Deque 实现对于它们能够包含的元素数没有固定限制，但此接口既支持有容量限制的双端队列，也支持没有固定大小限制的双端队列。

此接口定义在双端队列两端访问元素的方法。提供插入、移除和检查元素的方法。每种方法都存在两种形式：一种形式在操作失败时抛出异常，另一种形式返回一个特殊值（null 或 false，具体取决于操作）。插入操作的后一种形式是专为使用有容量限制的 Deque 实现设计的；在大多数实现中，插入操作不能失败。

下表总结了上述 12 种方法

![image-20231002201522266](C:\Users\qls\AppData\Roaming\Typora\typora-user-images\image-20231002201522266.png)

Deque接口扩展(继承)了 Queue 接口。在将双端队列用作队列时，将得到 FIFO（先进先出）行为。将元素添加到双端队列的末尾，从双端队列的开头移除元素。从 Queue 接口继承的方法完全等效于 Deque 方法，如下表所示

![image-20231002201550286](https://raw.githubusercontent.com/feixue-altaaa/picture/master/pic/202310022015353.png)

双端队列也可用作 LIFO（后进先出）堆栈。应优先使用此接口而不是遗留 Stack 类。在将双端队列用作堆栈时，元素被推入双端队列的开头并从双端队列开头弹出。堆栈方法完全等效于 Deque 方法，如下表所示

![image-20231002201615364](https://raw.githubusercontent.com/feixue-altaaa/picture/master/pic/202310022016467.png)
